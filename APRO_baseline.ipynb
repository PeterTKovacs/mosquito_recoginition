{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "APRO_baseline.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1IvBk--BwvvRi5mDSTYHS2iE0uS4C-UR1",
      "authorship_tag": "ABX9TyNK3JzbeqqCJ/8hkCg78mFR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PeterTKovacs/mosquito_recoginition/blob/master/APRO_baseline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3yzkjbDcPSjY"
      },
      "source": [
        "from PIL import Image\n",
        "from pathlib import Path\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import shutil\n",
        "import os\n",
        "from os.path import isfile, join\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "\n",
        "from torchvision import transforms\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wok6VHuiP_NA"
      },
      "source": [
        "class BaseLine:\n",
        "    def __init__(self,\n",
        "        input_images_path_ = 'drive/My Drive/AML2020/images',\n",
        "        csv_ = 'drive/My Drive/AML2020/train.csv',\n",
        "        input_path_ = 'drive/My Drive/AML2020',\n",
        "        train_path_ = 'drive/My Drive/AML2020/train4',\n",
        "        test_path_ = 'drive/My Drive/AML2020/test',\n",
        "        valid_path_ = 'drive/My Drive/AML2020/validation',\n",
        "                no_=4):\n",
        "        \n",
        "        import torch\n",
        "        import torchvision\n",
        "        \n",
        "        self.input_images_path = input_images_path_\n",
        "        self.csv = csv_\n",
        "        \n",
        "        self.input_path = input_path_\n",
        "        self.train_path = train_path_\n",
        "        self.test_path = test_path_\n",
        "        self.valid_path = valid_path_\n",
        "        self.no=no_\n",
        "\n",
        "\n",
        "    \n",
        "    def folder_generator(self):\n",
        "        import pandas as pd\n",
        "        import logging as log\n",
        "        import os\n",
        "        \n",
        "        csv_labels = pd.read_csv(self.csv)\n",
        "        \n",
        "        #images_paths = list(csv_labels['file'])\n",
        "        images_paths = csv_labels['file']\n",
        "        images_paths = [path.replace('images/', '') for path in images_paths]\n",
        "        \n",
        "        #images_labels = list(csv_labels['is_tiger'])\n",
        "        images_labels = csv_labels['is_tiger']\n",
        "        counter = 1\n",
        "        \n",
        "        tiger_path_train = os.path.join(self.train_path, 'tiger')\n",
        "        tiger1_path_train = os.path.join(self.train_path, 'tiger1')\n",
        "        tiger2_path_train = os.path.join(self.train_path, 'tiger2')\n",
        "        tiger3_path_train = os.path.join(self.train_path, 'tiger3')\n",
        "        tiger4_path_train = os.path.join(self.train_path, 'tiger4')\n",
        "        not_tiger_path_train = os.path.join(self.train_path, 'not_tiger')\n",
        "\n",
        "        \n",
        "        tiger_path_val = os.path.join(self.valid_path, 'tiger')\n",
        "        not_tiger_path_val = os.path.join(self.valid_path, 'not_tiger')\n",
        "        \n",
        "        test_unknown_path = os.path.join(self.test_path, 'unknown')\n",
        "        \n",
        "        os.mkdir(self.train_path)\n",
        "        os.mkdir(tiger_path_train)\n",
        "        os.mkdir(not_tiger_path_train)\n",
        "\n",
        "        os.mkdir(self.valid_path)\n",
        "        os.mkdir(tiger_path_val)\n",
        "        os.mkdir(not_tiger_path_val)\n",
        "        \n",
        "        os.mkdir(self.test_path)\n",
        "        os.mkdir(test_unknown_path)\n",
        "        \n",
        "        #Handling Train Images\n",
        "        print('###Handling Train Images')\n",
        "        for image_name, image_label in zip(images_paths, images_labels):\n",
        "            print('Copying image: {}, with label: {}'.format(image_name, image_label))    \n",
        "            if image_name.split('_')[0] == 'train' and counter % 5 != 0:\n",
        "                if image_label == 1:\n",
        "                    source_dir = os.path.join(self.input_images_path, image_name) \n",
        "                    dest_dir = os.path.join(tiger_path_train, image_name)\n",
        "                    shutil.copy(source_dir, dest_dir)\n",
        "                    counter += 1\n",
        "                    print('Copied image: {} to {}'.format(image_name, tiger_path_train))\n",
        "                else:\n",
        "                    source_dir = os.path.join(self.input_images_path, image_name) \n",
        "                    dest_dir = os.path.join(not_tiger_path_train, image_name)\n",
        "                    shutil.copy(source_dir, dest_dir)\n",
        "                    counter += 1\n",
        "                    print('Copied image: {} to {}'.format(image_name, not_tiger_path_train))\n",
        "            else:\n",
        "                if image_label == 1:\n",
        "                    source_dir = os.path.join(self.input_images_path, image_name) \n",
        "                    dest_dir = os.path.join(tiger_path_val, image_name)\n",
        "                    shutil.copy(source_dir, dest_dir)\n",
        "                    counter += 1\n",
        "                    print('Copied image: {} to {}'.format(image_name, tiger_path_val))\n",
        "                else:\n",
        "                    source_dir = os.path.join(self.input_images_path, image_name) \n",
        "                    dest_dir = os.path.join(not_tiger_path_val, image_name)\n",
        "                    shutil.copy(source_dir, dest_dir)\n",
        "                    counter += 1\n",
        "                    print('Copied image: {} to {}'.format(image_name, not_tiger_path_val))\n",
        "            \n",
        "    \n",
        "    def data_loader(self):\n",
        "        import torch\n",
        "        import torchvision\n",
        "        from torchvision import transforms\n",
        "        #ImageFolder\n",
        "        #Augementation for train and valid images\n",
        "        train_transforms = transforms.Compose([\n",
        "            transforms.RandomResizedCrop(224),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "        ])\n",
        "\n",
        "        val_transforms = transforms.Compose([\n",
        "            transforms.Resize((224, 224)),\n",
        "            transforms.ToTensor(), \n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "        ])\n",
        "\n",
        "        train_dataset = torchvision.datasets.ImageFolder(self.train_path, train_transforms)\n",
        "        #train_dataset = torchvision.datasets.ImageFolder(train_data, train_transforms)\n",
        "        validation_dataset = torchvision.datasets.ImageFolder(self.valid_path, val_transforms)\n",
        "        \n",
        "        #DataLoader\n",
        "        batch_size = 16\n",
        "        train_dataloader = torch.utils.data.DataLoader(\n",
        "            train_dataset, batch_size=batch_size, shuffle=True, num_workers=batch_size\n",
        "        )\n",
        "\n",
        "        validation_dataloader = torch.utils.data.DataLoader(\n",
        "            validation_dataset, batch_size=batch_size, shuffle=True, num_workers=batch_size\n",
        "        )\n",
        "        print(len(train_dataset), len(validation_dataset))\n",
        "        print(len(train_dataloader), len(validation_dataloader))\n",
        "        return train_dataloader, validation_dataloader\n",
        "    \n",
        "    def show_images(self, train_dataloader):\n",
        "        import numpy as np\n",
        "        import matplotlib.pyplot as plt\n",
        "        X_batch, y_batch = next(iter(train_dataloader))\n",
        "        mean = np.array([0.485, 0.456, 0.406])\n",
        "        std = np.array([[0.229, 0.224, 0.225]])\n",
        "        for index in range(5):\n",
        "            plt.title(y_batch[index])\n",
        "            plt.imshow(X_batch[index].permute(1,2,0).numpy() * std + mean, )\n",
        "            plt.show()\n",
        "    \n",
        "    def model(self):\n",
        "        from torchvision import models\n",
        "        import torch\n",
        "        model = models.resnet152(pretrained=True)\n",
        "        \n",
        "        \n",
        "        #Disable grad for all conv layers\n",
        "        for param in model.parameters():\n",
        "            param.requires_grad = False \n",
        "\n",
        "        model.fc = torch.nn.Linear(model.fc.in_features, 2)\n",
        "        device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "        model.to(device)\n",
        "        loss = torch.nn.CrossEntropyLoss()\n",
        "        optimizer = torch.optim.Adam(model.parameters(),amsgrad=True, lr=3.0e-4)\n",
        "       \n",
        "        \n",
        "        #Declay LR by a factor of 0.1 every 5th epoch\n",
        "        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size = 5, gamma = 0.4)\n",
        "        return model, loss, optimizer, scheduler, device\n",
        "    \n",
        "    def train_model(self, model, loss, optimizer, scheduler, train, validation, device, num_epochs):\n",
        "        import torch\n",
        "        from tqdm import tqdm\n",
        "\n",
        "        best_accuracy=-1\n",
        "        best_path='best'+str(self.no)+'.pth'\n",
        "\n",
        "        for epoch in range(num_epochs):\n",
        "            print('Epoch {}/{}:'.format(epoch, num_epochs - 1), flush=True)\n",
        "\n",
        "            # Each epoch has a training and validation phase\n",
        "            for phase in ['train', 'val']:\n",
        "                if phase == 'train':\n",
        "                    dataloader = train\n",
        "                    scheduler.step()\n",
        "                    \n",
        "                    model.train()  # Set model to training mode\n",
        "                else:\n",
        "                    dataloader = validation\n",
        "                    model.eval()   # Set model to evaluate mode\n",
        "\n",
        "                running_loss = 0.\n",
        "                running_acc = 0.\n",
        "                running_acc_tiger = 0.\n",
        "                running_acc_not_tiger = 0.\n",
        "\n",
        "                # Iterate over data.\n",
        "                for inputs, labels in tqdm(dataloader):\n",
        "                    inputs = inputs.to(device)\n",
        "                    labels = labels.to(device)\n",
        "\n",
        "                    optimizer.zero_grad()\n",
        "\n",
        "                    # forward and backward\n",
        "                    with torch.set_grad_enabled(phase == 'train'):\n",
        "                        preds = model(inputs)\n",
        "                        loss_value = loss(preds, labels)\n",
        "                        preds_class = preds.argmax(dim=1)\n",
        "\n",
        "                        # backward + optimize only if in training phase\n",
        "                        if phase == 'train':\n",
        "                            loss_value.backward()\n",
        "                            optimizer.step()\n",
        "\n",
        "                    # statistics\n",
        "                    running_loss += loss_value.item()\n",
        "                    running_acc += (preds_class == labels.data).float().mean()\n",
        "                    running_acc_tiger += (preds_class == 1).float().mean()\n",
        "                    running_acc_not_tiger += (preds_class == 0).float().mean()\n",
        "\n",
        "                epoch_loss = running_loss / len(dataloader)\n",
        "                epoch_acc = running_acc / len(dataloader)\n",
        "                epoch_acc_tiger = running_acc_tiger / len(dataloader)\n",
        "                epoch_acc_not_tiger = running_acc_not_tiger / len(dataloader)\n",
        "\n",
        "\n",
        "\n",
        "                print('{} Loss: {:.4f} Acc: {:.4f} Tiger Acc: {:.4f} Not Tiger Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc, epoch_acc_tiger, epoch_acc_not_tiger), flush=True)\n",
        "\n",
        "                if epoch_acc>best_accuracy and phase=='val' :\n",
        "                    \n",
        "                    self.create_checkpoint(model,optimizer,best_path,epoch,loss_value)\n",
        "                    best_accuracy=epoch_acc\n",
        "        \n",
        "        \n",
        "        self.load_from_checkpoint(model,optimizer,best_path)\n",
        "\n",
        "        return model\n",
        "\n",
        "    def create_checkpoint(self,model,optimizer,path,epoch,loss):\n",
        "        \n",
        "        # basically copied from the tutorial, \n",
        "        # https://pytorch.org/tutorials/recipes/recipes/saving_and_loading_a_general_checkpoint.html\n",
        "\n",
        "        torch.save({\n",
        "              'epoch': epoch,\n",
        "              'model_state_dict': model.state_dict(),\n",
        "              'optimizer_state_dict': optimizer.state_dict(),\n",
        "              'loss': loss,\n",
        "              }, path)\n",
        "        \n",
        "    def load_from_checkpoint(self,model,optimizer,path):\n",
        "        \n",
        "        # basically copied from the tutorial, \n",
        "        # https://pytorch.org/tutorials/recipes/recipes/saving_and_loading_a_general_checkpoint.html\n",
        "        \n",
        "        checkpoint = torch.load(path)\n",
        "        model.load_state_dict(checkpoint['model_state_dict'])\n",
        "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "\n",
        "        print('reloading best model of epoch %d, loss %f'%(checkpoint['epoch'],checkpoint['loss']))\n",
        "\n",
        "    \n",
        "    def run(self,num_ep=10):\n",
        "        #Processing data\n",
        "        #Job = BaseLine()\n",
        "        #Job.folder_generator()\n",
        "        #train_dataloader, validation_dataloader = Job.data_loader('drive/My Drive/AML2020/train0')\n",
        "        #train_dataloader1, validation_dataloader1 = Job.data_loader('drive/My Drive/AML2020/train1')\n",
        "        #train_dataloader2, validation_dataloader2 = Job.data_loader('drive/My Drive/AML2020/train2')\n",
        "        #train_dataloader3, validation_dataloader3 = Job.data_loader('drive/My Drive/AML2020/train3')\n",
        "        #train_dataloader4, validation_dataloader4 = Job.data_loader('drive/My Drive/AML2020/train4')\n",
        "        #Job.show_images(train_dataloader)\n",
        "        \n",
        "        #Define model\n",
        "        #model, loss, optimizer, scheduler, device = Job.model()\n",
        "        #print(model, loss, optimizer, scheduler)\n",
        "        #Train model \n",
        "        #trained_model = Job.train_model(model, loss, optimizer, scheduler, train_dataloader, validation_dataloader, device, num_epochs=num_ep)\n",
        "        #trained_model1 = Job.train_model(model, loss, optimizer, scheduler, train_dataloader1, validation_dataloader1, device, num_epochs=num_ep)\n",
        "        #trained_model2 = Job.train_model(model, loss, optimizer, scheduler, train_dataloader2, validation_dataloader2, device, num_epochs=num_ep)\n",
        "        #trained_model3 = Job.train_model(model, loss, optimizer, scheduler, train_dataloader3, validation_dataloader3, device, num_epochs=num_ep)\n",
        "        #trained_model4 = Job.train_model(model, loss, optimizer, scheduler, train_dataloader4, validation_dataloader4, device, num_epochs=num_ep)\n",
        "        #return trained_model, trained_model1, trained_model2, trained_model3, trained_model4\n",
        "        #return trained_model\n",
        "\n",
        "\n",
        "\n",
        "        train_dataloader, validation_dataloader = self.data_loader()\n",
        "        \n",
        "        #Define model\n",
        "        \n",
        "        model, loss, optimizer, scheduler, device = self.model()\n",
        "\n",
        "        #Train model \n",
        "        \n",
        "        trained_model = self.train_model(model, loss, optimizer, scheduler, train_dataloader, validation_dataloader,\n",
        "                                         device, num_epochs=num_ep)\n",
        "        return trained_model"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bg57S9lzQmLw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6651c3e0-57d9-444c-a57b-b4871d149f35"
      },
      "source": [
        "model = BaseLine().run()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1132 855\n",
            "71 54\n",
            "Epoch 0/9:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n",
            "100%|██████████| 71/71 [00:40<00:00,  1.77it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train Loss: 0.6313 Acc: 0.6291 Tiger Acc: 0.5713 Not Tiger Acc: 0.4287\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 54/54 [00:08<00:00,  6.01it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val Loss: 0.8789 Acc: 0.3218 Tiger Acc: 0.1682 Not Tiger Acc: 0.8318\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/9:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 71/71 [00:12<00:00,  5.85it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train Loss: 0.5297 Acc: 0.7280 Tiger Acc: 0.5126 Not Tiger Acc: 0.4874\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 54/54 [00:09<00:00,  5.76it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val Loss: 0.4286 Acc: 0.8353 Tiger Acc: 0.7450 Not Tiger Acc: 0.2550\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2/9:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 71/71 [00:11<00:00,  5.97it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train Loss: 0.4616 Acc: 0.8222 Tiger Acc: 0.4903 Not Tiger Acc: 0.5097\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 54/54 [00:08<00:00,  6.00it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val Loss: 0.4272 Acc: 0.8122 Tiger Acc: 0.7019 Not Tiger Acc: 0.2981\n",
            "Epoch 3/9:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 71/71 [00:11<00:00,  6.09it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train Loss: 0.4492 Acc: 0.8037 Tiger Acc: 0.4906 Not Tiger Acc: 0.5094\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 54/54 [00:09<00:00,  5.96it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val Loss: 0.4022 Acc: 0.8226 Tiger Acc: 0.7123 Not Tiger Acc: 0.2877\n",
            "Epoch 4/9:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 71/71 [00:11<00:00,  6.10it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train Loss: 0.4360 Acc: 0.8140 Tiger Acc: 0.5202 Not Tiger Acc: 0.4798\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 54/54 [00:09<00:00,  5.96it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val Loss: 0.4738 Acc: 0.7644 Tiger Acc: 0.6257 Not Tiger Acc: 0.3743\n",
            "Epoch 5/9:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 71/71 [00:11<00:00,  6.06it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train Loss: 0.4435 Acc: 0.7981 Tiger Acc: 0.4886 Not Tiger Acc: 0.5114\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 54/54 [00:09<00:00,  5.95it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val Loss: 0.3799 Acc: 0.8376 Tiger Acc: 0.7297 Not Tiger Acc: 0.2703\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 6/9:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 71/71 [00:11<00:00,  5.98it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train Loss: 0.4211 Acc: 0.8187 Tiger Acc: 0.4795 Not Tiger Acc: 0.5205\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 54/54 [00:09<00:00,  5.96it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val Loss: 0.4363 Acc: 0.7968 Tiger Acc: 0.6726 Not Tiger Acc: 0.3274\n",
            "Epoch 7/9:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 71/71 [00:11<00:00,  6.08it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train Loss: 0.4135 Acc: 0.8198 Tiger Acc: 0.4965 Not Tiger Acc: 0.5035\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 54/54 [00:09<00:00,  5.96it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val Loss: 0.3687 Acc: 0.8373 Tiger Acc: 0.7264 Not Tiger Acc: 0.2736\n",
            "Epoch 8/9:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 71/71 [00:11<00:00,  6.01it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train Loss: 0.4090 Acc: 0.8093 Tiger Acc: 0.5103 Not Tiger Acc: 0.4897\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 54/54 [00:08<00:00,  6.03it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val Loss: 0.3519 Acc: 0.8484 Tiger Acc: 0.7444 Not Tiger Acc: 0.2556\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 9/9:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 71/71 [00:11<00:00,  6.05it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train Loss: 0.4037 Acc: 0.8245 Tiger Acc: 0.5114 Not Tiger Acc: 0.4886\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 54/54 [00:09<00:00,  5.94it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val Loss: 0.3774 Acc: 0.8370 Tiger Acc: 0.7305 Not Tiger Acc: 0.2695\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "reloading best model of epoch 8, loss 0.180708\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fw0XqoqKJ78P"
      },
      "source": [
        "def model_(n,basedir='drive/My Drive/AML2020/'):\n",
        "    \n",
        "    \n",
        "    \n",
        "    model=BaseLine(\n",
        "    train_path_=os.path.join(basedir,'train'+str(n)),\n",
        "    valid_path_=os.path.join(basedir,'validation'),\n",
        "    test_path_=os.path.join(basedir,'test'),\n",
        "    no_=n)\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YxBn4sbRKuc_",
        "outputId": "7f878b78-253a-44db-98e7-ecce955781c8"
      },
      "source": [
        "models={}\n",
        "for i in range(5):\n",
        "    m=model_(i)\n",
        "    trained_m=m.run(num_ep=0)\n",
        "    models[i]=trained_m"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1136 855\n",
            "71 54\n",
            "reloading best model of epoch 1, loss 0.328908\n",
            "1132 855\n",
            "71 54\n",
            "reloading best model of epoch 8, loss 0.333934\n",
            "1132 855\n",
            "71 54\n",
            "reloading best model of epoch 2, loss 0.304487\n",
            "1132 855\n",
            "71 54\n",
            "reloading best model of epoch 2, loss 0.466655\n",
            "1132 855\n",
            "71 54\n",
            "reloading best model of epoch 8, loss 0.180708\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2z5ixf4H6oD"
      },
      "source": [
        "import pandas as pd\n",
        "import pickle\n",
        "\n",
        "def softmax(tensor):\n",
        "    \n",
        "    z=np.sum(np.exp(np.asarray(tensor)))\n",
        "    \n",
        "    return np.exp(np.asarray(tensor))/z\n",
        "\n",
        "\n",
        "def confidency(preds):\n",
        "    \n",
        "    confidencies=[]\n",
        "    \n",
        "    for pic in range(preds.shape[0]):\n",
        "        \n",
        "        confidencies.append(softmax(preds[pic,:])[1]) # guess that this is the tiger probability\n",
        "        \n",
        "    return confidencies"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47rh7_nuIJZm"
      },
      "source": [
        "test_tiger_names_all=os.listdir('drive/My Drive/AML2020/validation/tiger')\n",
        "test_other_names=os.listdir('drive/My Drive/AML2020/validation/not_tiger')\n",
        "test_tiger_names=random.sample(os.listdir('drive/My Drive/AML2020/validation/tiger'),len(test_other_names))\n",
        "\n",
        "batch_size=10\n",
        "counter=0\n",
        "to_batch=[]\n",
        "results={}\n",
        "\n",
        "val_transforms = transforms.Compose([\n",
        "            transforms.Resize((224, 224)),\n",
        "            transforms.ToTensor(), \n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "        ])\n",
        "\n",
        "for id_,model in models.items():\n",
        "    results[id_]={}\n",
        "    model.eval()\n",
        "\n",
        "for pic in test_other_names:\n",
        "    to_batch.append((pic,val_transforms(Image.open('drive/My Drive/AML2020/validation/not_tiger/'+pic))))\n",
        "    counter+=1\n",
        "    \n",
        "    if counter==batch_size:\n",
        "        \n",
        "        batch=torch.cat([(item[1].reshape(-1,3,224,224)).cuda() for item in to_batch ])\n",
        "        \n",
        "        for id_,model in models.items():\n",
        "            \n",
        "            conf=confidency(model(batch).cpu().detach().numpy())\n",
        "            \n",
        "            for idx,item in enumerate(to_batch):\n",
        "            \n",
        "                results[id_][item[0]]=conf[idx]\n",
        "                \n",
        "        counter=0\n",
        "        to_batch=[]\n",
        "        \n",
        "for pic in test_tiger_names:\n",
        "    to_batch.append((pic,val_transforms(Image.open('drive/My Drive/AML2020/validation/tiger/'+pic).convert('RGB'))))\n",
        "    counter+=1\n",
        "    \n",
        "    if counter==batch_size:\n",
        "        \n",
        "        batch=torch.cat([(item[1].reshape(-1,3,224,224)).cuda() for item in to_batch ])\n",
        "        \n",
        "        for id_,model in models.items():\n",
        "            \n",
        "            conf=confidency(model(batch).cpu().detach().numpy())\n",
        "            \n",
        "            for idx,item in enumerate(to_batch):\n",
        "            \n",
        "                results[id_][item[0]]=conf[idx]\n",
        "                \n",
        "        counter=0\n",
        "        to_batch=[]\n",
        "    \n",
        "            \n",
        "if len(to_batch)>0: #some pics remained unevaluated\n",
        "    \n",
        "    batch=torch.cat([(item[1].reshape(-1,3,224,224)).cuda() for item in to_batch ])\n",
        "        \n",
        "    for id_,model in models.items():\n",
        "\n",
        "        conf=confidency(model(batch).cpu().detach().numpy())\n",
        "\n",
        "        for idx,item in enumerate(to_batch):\n",
        "\n",
        "            results[id_][item[0]]=conf[idx]\n",
        "\n",
        "    counter=0\n",
        "    to_batch=[]"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xLDANh6VyTej"
      },
      "source": [
        "f=open('results_dictionary.txt','wb')\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HBn6N29xz16x"
      },
      "source": [
        "pickle.dump(results,f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Wc_MiJ7z2OD"
      },
      "source": [
        "import copy"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JO0VDYAL0o8b"
      },
      "source": [
        "rr=copy.deepcopy(results)"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xChE6Ebr0uap"
      },
      "source": [
        "for idx,model in models.items():\n",
        "    for key,value in rr[idx].items():\n",
        "        rr[idx][key]=list([value,])"
      ],
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "id": "ZlIrjwXw03fM",
        "outputId": "232ea898-5255-4861-ce81-b8b588f343b7"
      },
      "source": [
        "pd.DataFrame.from_dict(rr[0])"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>train_14.png</th>\n",
              "      <th>train_24.png</th>\n",
              "      <th>train_49.png</th>\n",
              "      <th>train_104.png</th>\n",
              "      <th>train_199.png</th>\n",
              "      <th>train_244.png</th>\n",
              "      <th>train_249.png</th>\n",
              "      <th>train_314.png</th>\n",
              "      <th>train_364.png</th>\n",
              "      <th>train_384.png</th>\n",
              "      <th>train_394.png</th>\n",
              "      <th>train_424.png</th>\n",
              "      <th>train_474.png</th>\n",
              "      <th>train_479.png</th>\n",
              "      <th>train_529.png</th>\n",
              "      <th>train_534.png</th>\n",
              "      <th>train_539.png</th>\n",
              "      <th>train_659.png</th>\n",
              "      <th>train_719.png</th>\n",
              "      <th>train_724.png</th>\n",
              "      <th>train_789.png</th>\n",
              "      <th>train_834.png</th>\n",
              "      <th>train_869.png</th>\n",
              "      <th>train_1004.png</th>\n",
              "      <th>train_1029.png</th>\n",
              "      <th>train_1034.png</th>\n",
              "      <th>train_1079.png</th>\n",
              "      <th>train_1084.png</th>\n",
              "      <th>train_1109.png</th>\n",
              "      <th>train_1124.png</th>\n",
              "      <th>train_1134.png</th>\n",
              "      <th>train_1139.png</th>\n",
              "      <th>train_1149.png</th>\n",
              "      <th>train_1179.png</th>\n",
              "      <th>train_1189.png</th>\n",
              "      <th>train_1229.png</th>\n",
              "      <th>train_1294.png</th>\n",
              "      <th>train_1299.png</th>\n",
              "      <th>train_1309.png</th>\n",
              "      <th>train_1339.png</th>\n",
              "      <th>...</th>\n",
              "      <th>train_3059.png</th>\n",
              "      <th>train_1064.png</th>\n",
              "      <th>train_2304.png</th>\n",
              "      <th>train_1989.png</th>\n",
              "      <th>train_2269.png</th>\n",
              "      <th>train_1834.png</th>\n",
              "      <th>train_1859.png</th>\n",
              "      <th>train_1604.png</th>\n",
              "      <th>train_1579.png</th>\n",
              "      <th>train_2444.png</th>\n",
              "      <th>train_2989.png</th>\n",
              "      <th>train_2794.png</th>\n",
              "      <th>train_3359.png</th>\n",
              "      <th>train_2599.png</th>\n",
              "      <th>train_3014.png</th>\n",
              "      <th>train_319.png</th>\n",
              "      <th>train_4154.png</th>\n",
              "      <th>train_2049.png</th>\n",
              "      <th>train_1184.png</th>\n",
              "      <th>train_1659.png</th>\n",
              "      <th>train_654.png</th>\n",
              "      <th>train_2124.png</th>\n",
              "      <th>train_3504.png</th>\n",
              "      <th>train_3144.png</th>\n",
              "      <th>train_174.png</th>\n",
              "      <th>train_324.png</th>\n",
              "      <th>train_3784.png</th>\n",
              "      <th>train_3184.png</th>\n",
              "      <th>train_2464.png</th>\n",
              "      <th>train_2864.png</th>\n",
              "      <th>train_3304.png</th>\n",
              "      <th>train_4114.png</th>\n",
              "      <th>train_2339.png</th>\n",
              "      <th>train_3379.png</th>\n",
              "      <th>train_4199.png</th>\n",
              "      <th>train_3984.png</th>\n",
              "      <th>train_154.png</th>\n",
              "      <th>train_224.png</th>\n",
              "      <th>train_2789.png</th>\n",
              "      <th>train_1729.png</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.209736</td>\n",
              "      <td>0.302952</td>\n",
              "      <td>0.403749</td>\n",
              "      <td>0.794819</td>\n",
              "      <td>0.555901</td>\n",
              "      <td>0.357363</td>\n",
              "      <td>0.421041</td>\n",
              "      <td>0.756719</td>\n",
              "      <td>0.117494</td>\n",
              "      <td>0.484588</td>\n",
              "      <td>0.428709</td>\n",
              "      <td>0.681044</td>\n",
              "      <td>0.732484</td>\n",
              "      <td>0.73926</td>\n",
              "      <td>0.791599</td>\n",
              "      <td>0.261638</td>\n",
              "      <td>0.463211</td>\n",
              "      <td>0.435713</td>\n",
              "      <td>0.427354</td>\n",
              "      <td>0.507778</td>\n",
              "      <td>0.498742</td>\n",
              "      <td>0.481971</td>\n",
              "      <td>0.509859</td>\n",
              "      <td>0.45569</td>\n",
              "      <td>0.304075</td>\n",
              "      <td>0.51793</td>\n",
              "      <td>0.625527</td>\n",
              "      <td>0.568673</td>\n",
              "      <td>0.355695</td>\n",
              "      <td>0.499256</td>\n",
              "      <td>0.518045</td>\n",
              "      <td>0.539013</td>\n",
              "      <td>0.458135</td>\n",
              "      <td>0.245634</td>\n",
              "      <td>0.282906</td>\n",
              "      <td>0.693802</td>\n",
              "      <td>0.766299</td>\n",
              "      <td>0.762627</td>\n",
              "      <td>0.296871</td>\n",
              "      <td>0.778213</td>\n",
              "      <td>...</td>\n",
              "      <td>0.351072</td>\n",
              "      <td>0.945673</td>\n",
              "      <td>0.822857</td>\n",
              "      <td>0.902167</td>\n",
              "      <td>0.858425</td>\n",
              "      <td>0.814976</td>\n",
              "      <td>0.766667</td>\n",
              "      <td>0.753307</td>\n",
              "      <td>0.835444</td>\n",
              "      <td>0.815474</td>\n",
              "      <td>0.844762</td>\n",
              "      <td>0.822735</td>\n",
              "      <td>0.703114</td>\n",
              "      <td>0.44943</td>\n",
              "      <td>0.791587</td>\n",
              "      <td>0.836566</td>\n",
              "      <td>0.881824</td>\n",
              "      <td>0.935365</td>\n",
              "      <td>0.939269</td>\n",
              "      <td>0.885314</td>\n",
              "      <td>0.764981</td>\n",
              "      <td>0.865804</td>\n",
              "      <td>0.628737</td>\n",
              "      <td>0.842267</td>\n",
              "      <td>0.762333</td>\n",
              "      <td>0.90339</td>\n",
              "      <td>0.943659</td>\n",
              "      <td>0.883013</td>\n",
              "      <td>0.929438</td>\n",
              "      <td>0.633835</td>\n",
              "      <td>0.717058</td>\n",
              "      <td>0.678885</td>\n",
              "      <td>0.857498</td>\n",
              "      <td>0.755521</td>\n",
              "      <td>0.893088</td>\n",
              "      <td>0.798566</td>\n",
              "      <td>0.828486</td>\n",
              "      <td>0.807249</td>\n",
              "      <td>0.822476</td>\n",
              "      <td>0.934474</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1 rows × 272 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   train_14.png  train_24.png  ...  train_2789.png  train_1729.png\n",
              "0      0.209736      0.302952  ...        0.822476        0.934474\n",
              "\n",
              "[1 rows x 272 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0MsYN3it1DhB"
      },
      "source": [
        "tabular_res=pd.concat([pd.DataFrame.from_dict(rr[i]) for i in range(5)])"
      ],
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "id": "X7-6GJhL1E59",
        "outputId": "c978dc72-e63d-4fc4-b0de-5d1998883771"
      },
      "source": [
        "tabular_res"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>train_14.png</th>\n",
              "      <th>train_24.png</th>\n",
              "      <th>train_49.png</th>\n",
              "      <th>train_104.png</th>\n",
              "      <th>train_199.png</th>\n",
              "      <th>train_244.png</th>\n",
              "      <th>train_249.png</th>\n",
              "      <th>train_314.png</th>\n",
              "      <th>train_364.png</th>\n",
              "      <th>train_384.png</th>\n",
              "      <th>train_394.png</th>\n",
              "      <th>train_424.png</th>\n",
              "      <th>train_474.png</th>\n",
              "      <th>train_479.png</th>\n",
              "      <th>train_529.png</th>\n",
              "      <th>train_534.png</th>\n",
              "      <th>train_539.png</th>\n",
              "      <th>train_659.png</th>\n",
              "      <th>train_719.png</th>\n",
              "      <th>train_724.png</th>\n",
              "      <th>train_789.png</th>\n",
              "      <th>train_834.png</th>\n",
              "      <th>train_869.png</th>\n",
              "      <th>train_1004.png</th>\n",
              "      <th>train_1029.png</th>\n",
              "      <th>train_1034.png</th>\n",
              "      <th>train_1079.png</th>\n",
              "      <th>train_1084.png</th>\n",
              "      <th>train_1109.png</th>\n",
              "      <th>train_1124.png</th>\n",
              "      <th>train_1134.png</th>\n",
              "      <th>train_1139.png</th>\n",
              "      <th>train_1149.png</th>\n",
              "      <th>train_1179.png</th>\n",
              "      <th>train_1189.png</th>\n",
              "      <th>train_1229.png</th>\n",
              "      <th>train_1294.png</th>\n",
              "      <th>train_1299.png</th>\n",
              "      <th>train_1309.png</th>\n",
              "      <th>train_1339.png</th>\n",
              "      <th>...</th>\n",
              "      <th>train_1279.png</th>\n",
              "      <th>train_1284.png</th>\n",
              "      <th>train_1289.png</th>\n",
              "      <th>train_1304.png</th>\n",
              "      <th>train_1314.png</th>\n",
              "      <th>train_1319.png</th>\n",
              "      <th>train_1324.png</th>\n",
              "      <th>train_1329.png</th>\n",
              "      <th>train_1334.png</th>\n",
              "      <th>train_1344.png</th>\n",
              "      <th>train_1349.png</th>\n",
              "      <th>train_1359.png</th>\n",
              "      <th>train_1369.png</th>\n",
              "      <th>train_1374.png</th>\n",
              "      <th>train_1379.png</th>\n",
              "      <th>train_1384.png</th>\n",
              "      <th>train_1389.png</th>\n",
              "      <th>train_1394.png</th>\n",
              "      <th>train_1399.png</th>\n",
              "      <th>train_1404.png</th>\n",
              "      <th>train_1409.png</th>\n",
              "      <th>train_1414.png</th>\n",
              "      <th>train_1419.png</th>\n",
              "      <th>train_1424.png</th>\n",
              "      <th>train_1429.png</th>\n",
              "      <th>train_1434.png</th>\n",
              "      <th>train_1439.png</th>\n",
              "      <th>train_1444.png</th>\n",
              "      <th>train_1449.png</th>\n",
              "      <th>train_1454.png</th>\n",
              "      <th>train_1459.png</th>\n",
              "      <th>train_1469.png</th>\n",
              "      <th>train_1479.png</th>\n",
              "      <th>train_1484.png</th>\n",
              "      <th>train_1489.png</th>\n",
              "      <th>train_1494.png</th>\n",
              "      <th>train_1499.png</th>\n",
              "      <th>train_1504.png</th>\n",
              "      <th>train_1509.png</th>\n",
              "      <th>train_1514.png</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.209736</td>\n",
              "      <td>0.302952</td>\n",
              "      <td>0.403749</td>\n",
              "      <td>0.794819</td>\n",
              "      <td>0.555901</td>\n",
              "      <td>0.357363</td>\n",
              "      <td>0.421041</td>\n",
              "      <td>0.756719</td>\n",
              "      <td>0.117494</td>\n",
              "      <td>0.484588</td>\n",
              "      <td>0.428709</td>\n",
              "      <td>0.681044</td>\n",
              "      <td>0.732484</td>\n",
              "      <td>0.739260</td>\n",
              "      <td>0.791599</td>\n",
              "      <td>0.261638</td>\n",
              "      <td>0.463211</td>\n",
              "      <td>0.435713</td>\n",
              "      <td>0.427354</td>\n",
              "      <td>0.507778</td>\n",
              "      <td>0.498742</td>\n",
              "      <td>0.481971</td>\n",
              "      <td>0.509859</td>\n",
              "      <td>0.455690</td>\n",
              "      <td>0.304075</td>\n",
              "      <td>0.517930</td>\n",
              "      <td>0.625527</td>\n",
              "      <td>0.568673</td>\n",
              "      <td>0.355695</td>\n",
              "      <td>0.499256</td>\n",
              "      <td>0.518045</td>\n",
              "      <td>0.539013</td>\n",
              "      <td>0.458135</td>\n",
              "      <td>0.245634</td>\n",
              "      <td>0.282906</td>\n",
              "      <td>0.693802</td>\n",
              "      <td>0.766299</td>\n",
              "      <td>0.762627</td>\n",
              "      <td>0.296871</td>\n",
              "      <td>0.778213</td>\n",
              "      <td>...</td>\n",
              "      <td>0.958302</td>\n",
              "      <td>0.903137</td>\n",
              "      <td>0.915827</td>\n",
              "      <td>0.709422</td>\n",
              "      <td>0.826865</td>\n",
              "      <td>0.761198</td>\n",
              "      <td>0.556625</td>\n",
              "      <td>0.914706</td>\n",
              "      <td>0.804403</td>\n",
              "      <td>0.941148</td>\n",
              "      <td>0.790828</td>\n",
              "      <td>0.975146</td>\n",
              "      <td>0.818374</td>\n",
              "      <td>0.950069</td>\n",
              "      <td>0.698066</td>\n",
              "      <td>0.976259</td>\n",
              "      <td>0.579234</td>\n",
              "      <td>0.924904</td>\n",
              "      <td>0.846861</td>\n",
              "      <td>0.713022</td>\n",
              "      <td>0.909954</td>\n",
              "      <td>0.883279</td>\n",
              "      <td>0.888295</td>\n",
              "      <td>0.850803</td>\n",
              "      <td>0.829015</td>\n",
              "      <td>0.334472</td>\n",
              "      <td>0.582512</td>\n",
              "      <td>0.714281</td>\n",
              "      <td>0.782257</td>\n",
              "      <td>0.709204</td>\n",
              "      <td>0.788649</td>\n",
              "      <td>0.855719</td>\n",
              "      <td>0.867720</td>\n",
              "      <td>0.534554</td>\n",
              "      <td>0.930075</td>\n",
              "      <td>0.605718</td>\n",
              "      <td>0.701639</td>\n",
              "      <td>0.842552</td>\n",
              "      <td>0.860819</td>\n",
              "      <td>0.823419</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.140258</td>\n",
              "      <td>0.163531</td>\n",
              "      <td>0.210985</td>\n",
              "      <td>0.759600</td>\n",
              "      <td>0.362302</td>\n",
              "      <td>0.080574</td>\n",
              "      <td>0.220442</td>\n",
              "      <td>0.437065</td>\n",
              "      <td>0.020906</td>\n",
              "      <td>0.220081</td>\n",
              "      <td>0.238849</td>\n",
              "      <td>0.615121</td>\n",
              "      <td>0.687314</td>\n",
              "      <td>0.462181</td>\n",
              "      <td>0.534164</td>\n",
              "      <td>0.133865</td>\n",
              "      <td>0.370064</td>\n",
              "      <td>0.241967</td>\n",
              "      <td>0.146943</td>\n",
              "      <td>0.305404</td>\n",
              "      <td>0.144578</td>\n",
              "      <td>0.314170</td>\n",
              "      <td>0.125502</td>\n",
              "      <td>0.620888</td>\n",
              "      <td>0.100052</td>\n",
              "      <td>0.297949</td>\n",
              "      <td>0.493437</td>\n",
              "      <td>0.404515</td>\n",
              "      <td>0.055006</td>\n",
              "      <td>0.143297</td>\n",
              "      <td>0.139867</td>\n",
              "      <td>0.181729</td>\n",
              "      <td>0.312294</td>\n",
              "      <td>0.106453</td>\n",
              "      <td>0.103080</td>\n",
              "      <td>0.682907</td>\n",
              "      <td>0.718419</td>\n",
              "      <td>0.730659</td>\n",
              "      <td>0.067513</td>\n",
              "      <td>0.880105</td>\n",
              "      <td>...</td>\n",
              "      <td>0.968526</td>\n",
              "      <td>0.950648</td>\n",
              "      <td>0.928355</td>\n",
              "      <td>0.807178</td>\n",
              "      <td>0.851160</td>\n",
              "      <td>0.858070</td>\n",
              "      <td>0.558053</td>\n",
              "      <td>0.912332</td>\n",
              "      <td>0.802267</td>\n",
              "      <td>0.982297</td>\n",
              "      <td>0.839294</td>\n",
              "      <td>0.997551</td>\n",
              "      <td>0.940110</td>\n",
              "      <td>0.962747</td>\n",
              "      <td>0.544839</td>\n",
              "      <td>0.992510</td>\n",
              "      <td>0.574529</td>\n",
              "      <td>0.964537</td>\n",
              "      <td>0.936402</td>\n",
              "      <td>0.710499</td>\n",
              "      <td>0.943100</td>\n",
              "      <td>0.972436</td>\n",
              "      <td>0.842301</td>\n",
              "      <td>0.771888</td>\n",
              "      <td>0.859269</td>\n",
              "      <td>0.288327</td>\n",
              "      <td>0.364556</td>\n",
              "      <td>0.715882</td>\n",
              "      <td>0.573327</td>\n",
              "      <td>0.839148</td>\n",
              "      <td>0.841377</td>\n",
              "      <td>0.882068</td>\n",
              "      <td>0.924490</td>\n",
              "      <td>0.614706</td>\n",
              "      <td>0.944547</td>\n",
              "      <td>0.813964</td>\n",
              "      <td>0.688086</td>\n",
              "      <td>0.886713</td>\n",
              "      <td>0.953959</td>\n",
              "      <td>0.915703</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.289888</td>\n",
              "      <td>0.169453</td>\n",
              "      <td>0.446861</td>\n",
              "      <td>0.781015</td>\n",
              "      <td>0.474826</td>\n",
              "      <td>0.208090</td>\n",
              "      <td>0.231537</td>\n",
              "      <td>0.634385</td>\n",
              "      <td>0.080451</td>\n",
              "      <td>0.400536</td>\n",
              "      <td>0.329385</td>\n",
              "      <td>0.706643</td>\n",
              "      <td>0.671806</td>\n",
              "      <td>0.443191</td>\n",
              "      <td>0.601163</td>\n",
              "      <td>0.293394</td>\n",
              "      <td>0.511332</td>\n",
              "      <td>0.328965</td>\n",
              "      <td>0.309848</td>\n",
              "      <td>0.379094</td>\n",
              "      <td>0.265719</td>\n",
              "      <td>0.323338</td>\n",
              "      <td>0.381329</td>\n",
              "      <td>0.432387</td>\n",
              "      <td>0.286150</td>\n",
              "      <td>0.509252</td>\n",
              "      <td>0.474230</td>\n",
              "      <td>0.585852</td>\n",
              "      <td>0.193408</td>\n",
              "      <td>0.332631</td>\n",
              "      <td>0.363611</td>\n",
              "      <td>0.302796</td>\n",
              "      <td>0.404430</td>\n",
              "      <td>0.181492</td>\n",
              "      <td>0.217177</td>\n",
              "      <td>0.739133</td>\n",
              "      <td>0.766585</td>\n",
              "      <td>0.752206</td>\n",
              "      <td>0.206051</td>\n",
              "      <td>0.795320</td>\n",
              "      <td>...</td>\n",
              "      <td>0.942796</td>\n",
              "      <td>0.905074</td>\n",
              "      <td>0.902101</td>\n",
              "      <td>0.772700</td>\n",
              "      <td>0.708904</td>\n",
              "      <td>0.784616</td>\n",
              "      <td>0.528510</td>\n",
              "      <td>0.861282</td>\n",
              "      <td>0.743546</td>\n",
              "      <td>0.964725</td>\n",
              "      <td>0.717268</td>\n",
              "      <td>0.979087</td>\n",
              "      <td>0.863714</td>\n",
              "      <td>0.942825</td>\n",
              "      <td>0.536634</td>\n",
              "      <td>0.969716</td>\n",
              "      <td>0.675530</td>\n",
              "      <td>0.932491</td>\n",
              "      <td>0.856450</td>\n",
              "      <td>0.633190</td>\n",
              "      <td>0.926798</td>\n",
              "      <td>0.830919</td>\n",
              "      <td>0.775776</td>\n",
              "      <td>0.809908</td>\n",
              "      <td>0.856080</td>\n",
              "      <td>0.369874</td>\n",
              "      <td>0.508964</td>\n",
              "      <td>0.774885</td>\n",
              "      <td>0.592175</td>\n",
              "      <td>0.848643</td>\n",
              "      <td>0.834473</td>\n",
              "      <td>0.816150</td>\n",
              "      <td>0.901507</td>\n",
              "      <td>0.660631</td>\n",
              "      <td>0.937495</td>\n",
              "      <td>0.711108</td>\n",
              "      <td>0.780179</td>\n",
              "      <td>0.805622</td>\n",
              "      <td>0.924992</td>\n",
              "      <td>0.842946</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.221980</td>\n",
              "      <td>0.161097</td>\n",
              "      <td>0.523462</td>\n",
              "      <td>0.636929</td>\n",
              "      <td>0.343989</td>\n",
              "      <td>0.214602</td>\n",
              "      <td>0.200371</td>\n",
              "      <td>0.557144</td>\n",
              "      <td>0.054974</td>\n",
              "      <td>0.343143</td>\n",
              "      <td>0.367335</td>\n",
              "      <td>0.634559</td>\n",
              "      <td>0.621180</td>\n",
              "      <td>0.529309</td>\n",
              "      <td>0.507047</td>\n",
              "      <td>0.149283</td>\n",
              "      <td>0.346270</td>\n",
              "      <td>0.261988</td>\n",
              "      <td>0.295835</td>\n",
              "      <td>0.348855</td>\n",
              "      <td>0.311465</td>\n",
              "      <td>0.368055</td>\n",
              "      <td>0.340550</td>\n",
              "      <td>0.533217</td>\n",
              "      <td>0.167505</td>\n",
              "      <td>0.431024</td>\n",
              "      <td>0.509012</td>\n",
              "      <td>0.354952</td>\n",
              "      <td>0.152064</td>\n",
              "      <td>0.282278</td>\n",
              "      <td>0.291604</td>\n",
              "      <td>0.244887</td>\n",
              "      <td>0.334682</td>\n",
              "      <td>0.202897</td>\n",
              "      <td>0.167517</td>\n",
              "      <td>0.729442</td>\n",
              "      <td>0.716787</td>\n",
              "      <td>0.556351</td>\n",
              "      <td>0.206270</td>\n",
              "      <td>0.786097</td>\n",
              "      <td>...</td>\n",
              "      <td>0.970260</td>\n",
              "      <td>0.929344</td>\n",
              "      <td>0.907360</td>\n",
              "      <td>0.626607</td>\n",
              "      <td>0.618696</td>\n",
              "      <td>0.781000</td>\n",
              "      <td>0.527184</td>\n",
              "      <td>0.885260</td>\n",
              "      <td>0.813891</td>\n",
              "      <td>0.953549</td>\n",
              "      <td>0.710761</td>\n",
              "      <td>0.986309</td>\n",
              "      <td>0.840814</td>\n",
              "      <td>0.953698</td>\n",
              "      <td>0.602942</td>\n",
              "      <td>0.977843</td>\n",
              "      <td>0.556236</td>\n",
              "      <td>0.896943</td>\n",
              "      <td>0.896644</td>\n",
              "      <td>0.619903</td>\n",
              "      <td>0.899084</td>\n",
              "      <td>0.841505</td>\n",
              "      <td>0.857418</td>\n",
              "      <td>0.831139</td>\n",
              "      <td>0.765478</td>\n",
              "      <td>0.202467</td>\n",
              "      <td>0.454299</td>\n",
              "      <td>0.683115</td>\n",
              "      <td>0.638963</td>\n",
              "      <td>0.813120</td>\n",
              "      <td>0.847827</td>\n",
              "      <td>0.825423</td>\n",
              "      <td>0.810846</td>\n",
              "      <td>0.593125</td>\n",
              "      <td>0.939200</td>\n",
              "      <td>0.658559</td>\n",
              "      <td>0.752047</td>\n",
              "      <td>0.708722</td>\n",
              "      <td>0.902307</td>\n",
              "      <td>0.809064</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.090144</td>\n",
              "      <td>0.093939</td>\n",
              "      <td>0.145097</td>\n",
              "      <td>0.701267</td>\n",
              "      <td>0.192143</td>\n",
              "      <td>0.086326</td>\n",
              "      <td>0.089402</td>\n",
              "      <td>0.371727</td>\n",
              "      <td>0.018852</td>\n",
              "      <td>0.151425</td>\n",
              "      <td>0.193100</td>\n",
              "      <td>0.596637</td>\n",
              "      <td>0.606760</td>\n",
              "      <td>0.365069</td>\n",
              "      <td>0.605331</td>\n",
              "      <td>0.058512</td>\n",
              "      <td>0.194024</td>\n",
              "      <td>0.121606</td>\n",
              "      <td>0.070489</td>\n",
              "      <td>0.277815</td>\n",
              "      <td>0.101503</td>\n",
              "      <td>0.157022</td>\n",
              "      <td>0.183167</td>\n",
              "      <td>0.213315</td>\n",
              "      <td>0.074742</td>\n",
              "      <td>0.188322</td>\n",
              "      <td>0.314655</td>\n",
              "      <td>0.376179</td>\n",
              "      <td>0.075239</td>\n",
              "      <td>0.185620</td>\n",
              "      <td>0.175685</td>\n",
              "      <td>0.152876</td>\n",
              "      <td>0.111804</td>\n",
              "      <td>0.050277</td>\n",
              "      <td>0.086152</td>\n",
              "      <td>0.627949</td>\n",
              "      <td>0.561349</td>\n",
              "      <td>0.724133</td>\n",
              "      <td>0.057813</td>\n",
              "      <td>0.738539</td>\n",
              "      <td>...</td>\n",
              "      <td>0.981916</td>\n",
              "      <td>0.889203</td>\n",
              "      <td>0.925570</td>\n",
              "      <td>0.662761</td>\n",
              "      <td>0.534860</td>\n",
              "      <td>0.826827</td>\n",
              "      <td>0.307865</td>\n",
              "      <td>0.892700</td>\n",
              "      <td>0.644166</td>\n",
              "      <td>0.972287</td>\n",
              "      <td>0.703075</td>\n",
              "      <td>0.991782</td>\n",
              "      <td>0.875763</td>\n",
              "      <td>0.947268</td>\n",
              "      <td>0.548272</td>\n",
              "      <td>0.987211</td>\n",
              "      <td>0.459921</td>\n",
              "      <td>0.958138</td>\n",
              "      <td>0.880717</td>\n",
              "      <td>0.576119</td>\n",
              "      <td>0.912384</td>\n",
              "      <td>0.869594</td>\n",
              "      <td>0.808911</td>\n",
              "      <td>0.749290</td>\n",
              "      <td>0.861234</td>\n",
              "      <td>0.245213</td>\n",
              "      <td>0.229822</td>\n",
              "      <td>0.769643</td>\n",
              "      <td>0.538714</td>\n",
              "      <td>0.791167</td>\n",
              "      <td>0.831178</td>\n",
              "      <td>0.936756</td>\n",
              "      <td>0.942794</td>\n",
              "      <td>0.452735</td>\n",
              "      <td>0.929823</td>\n",
              "      <td>0.583383</td>\n",
              "      <td>0.566129</td>\n",
              "      <td>0.833653</td>\n",
              "      <td>0.915061</td>\n",
              "      <td>0.837263</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 855 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   train_14.png  train_24.png  ...  train_1509.png  train_1514.png\n",
              "0      0.209736      0.302952  ...        0.860819        0.823419\n",
              "0      0.140258      0.163531  ...        0.953959        0.915703\n",
              "0      0.289888      0.169453  ...        0.924992        0.842946\n",
              "0      0.221980      0.161097  ...        0.902307        0.809064\n",
              "0      0.090144      0.093939  ...        0.915061        0.837263\n",
              "\n",
              "[5 rows x 855 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "RaaRIZns1Qec",
        "outputId": "223dec1c-d0c9-4f0e-eed0-254044865372"
      },
      "source": [
        "tabular_res.index=[0,1,2,3,4]\n",
        "data=tabular_res.transpose()\n",
        "data.head()"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>train_14.png</th>\n",
              "      <td>0.209736</td>\n",
              "      <td>0.140258</td>\n",
              "      <td>0.289888</td>\n",
              "      <td>0.221980</td>\n",
              "      <td>0.090144</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>train_24.png</th>\n",
              "      <td>0.302952</td>\n",
              "      <td>0.163531</td>\n",
              "      <td>0.169453</td>\n",
              "      <td>0.161097</td>\n",
              "      <td>0.093939</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>train_49.png</th>\n",
              "      <td>0.403749</td>\n",
              "      <td>0.210985</td>\n",
              "      <td>0.446861</td>\n",
              "      <td>0.523462</td>\n",
              "      <td>0.145097</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>train_104.png</th>\n",
              "      <td>0.794819</td>\n",
              "      <td>0.759600</td>\n",
              "      <td>0.781015</td>\n",
              "      <td>0.636929</td>\n",
              "      <td>0.701267</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>train_199.png</th>\n",
              "      <td>0.555901</td>\n",
              "      <td>0.362302</td>\n",
              "      <td>0.474826</td>\n",
              "      <td>0.343989</td>\n",
              "      <td>0.192143</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                      0         1         2         3         4\n",
              "train_14.png   0.209736  0.140258  0.289888  0.221980  0.090144\n",
              "train_24.png   0.302952  0.163531  0.169453  0.161097  0.093939\n",
              "train_49.png   0.403749  0.210985  0.446861  0.523462  0.145097\n",
              "train_104.png  0.794819  0.759600  0.781015  0.636929  0.701267\n",
              "train_199.png  0.555901  0.362302  0.474826  0.343989  0.192143"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lIdjblZnyjk8"
      },
      "source": [
        "labels = pd.read_csv('drive/My Drive/AML2020/train.csv')\n",
        "indeces = []\n",
        "for pic in list(data.index):\n",
        "    index = list(labels['file']).index('images/'+pic)\n",
        "    indeces.append(index)\n",
        "\n",
        "labels_data = labels.iloc[indeces]\n",
        "data['labels'] = list(labels_data['is_tiger'])"
      ],
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "3y6rpaK93JaY",
        "outputId": "0aee6814-9d03-40e8-b043-073720ea056b"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>train_14.png</th>\n",
              "      <td>0.209736</td>\n",
              "      <td>0.140258</td>\n",
              "      <td>0.289888</td>\n",
              "      <td>0.221980</td>\n",
              "      <td>0.090144</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>train_24.png</th>\n",
              "      <td>0.302952</td>\n",
              "      <td>0.163531</td>\n",
              "      <td>0.169453</td>\n",
              "      <td>0.161097</td>\n",
              "      <td>0.093939</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>train_49.png</th>\n",
              "      <td>0.403749</td>\n",
              "      <td>0.210985</td>\n",
              "      <td>0.446861</td>\n",
              "      <td>0.523462</td>\n",
              "      <td>0.145097</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>train_104.png</th>\n",
              "      <td>0.794819</td>\n",
              "      <td>0.759600</td>\n",
              "      <td>0.781015</td>\n",
              "      <td>0.636929</td>\n",
              "      <td>0.701267</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>train_199.png</th>\n",
              "      <td>0.555901</td>\n",
              "      <td>0.362302</td>\n",
              "      <td>0.474826</td>\n",
              "      <td>0.343989</td>\n",
              "      <td>0.192143</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                      0         1         2         3         4  labels\n",
              "train_14.png   0.209736  0.140258  0.289888  0.221980  0.090144       0\n",
              "train_24.png   0.302952  0.163531  0.169453  0.161097  0.093939       0\n",
              "train_49.png   0.403749  0.210985  0.446861  0.523462  0.145097       0\n",
              "train_104.png  0.794819  0.759600  0.781015  0.636929  0.701267       0\n",
              "train_199.png  0.555901  0.362302  0.474826  0.343989  0.192143       0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BHEUp1gp303-"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import svm\n",
        "X, y = data[[0,1,2,3,4]], data['labels']\n",
        "clf = LogisticRegression(random_state=0).fit(X,y)\n",
        "clf2 = svm.SVC().fit(X,y)"
      ],
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P12ZhR4o646x"
      },
      "source": [
        "weights_tiger=[]\n",
        "weights_not_tiger=[]\n",
        "for i in range(len(data)):\n",
        "  if data['labels'][i] == 1:\n",
        "    weights_not_tiger.append(0)\n",
        "    weights_tiger.append(1/(sum(data['labels'])))\n",
        "  else:\n",
        "    weights_not_tiger.append(1/(len(data) - sum(data['labels'])))\n",
        "    weights_tiger.append(0)\n"
      ],
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fc7XLje1A-q5"
      },
      "source": [
        "Logistic regression accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JCcGX9TX7bfG",
        "outputId": "fb58a6ad-6ea1-4a78-ae2b-a0757d1ded80"
      },
      "source": [
        "print('Overall accuracy: {:.4f} Not Tiger accuracy: {:.4f} Tiger accuracy: {:.4f}'.format(clf.score(X,y),clf.score(X,y,sample_weight=weights_not_tiger),clf.score(X,y,sample_weight=weights_tiger)))"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overall accuracy: 0.8346 Not Tiger accuracy: 0.8088 Tiger accuracy: 0.8603\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O5eRgDhhBBTk"
      },
      "source": [
        "SVM accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mAnAuNJk-peR",
        "outputId": "230e2bb6-90cc-4593-951d-aefe9ed02daa"
      },
      "source": [
        "print('Overall accuracy: {:.4f} Not Tiger accuracy: {:.4f} Tiger accuracy: {:.4f}'.format(clf2.score(X,y),clf2.score(X,y,sample_weight=weights_not_tiger),clf2.score(X,y,sample_weight=weights_tiger)))"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overall accuracy: 0.8603 Not Tiger accuracy: 0.8897 Tiger accuracy: 0.8309\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}