{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "APRO_baseline.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1IvBk--BwvvRi5mDSTYHS2iE0uS4C-UR1",
      "authorship_tag": "ABX9TyOAC5acbjTUrFf6cSERYnK9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PeterTKovacs/mosquito_recoginition/blob/main/APRO_baseline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3yzkjbDcPSjY"
      },
      "source": [
        "from PIL import Image\n",
        "from pathlib import Path\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import shutil\n",
        "import os\n",
        "from os.path import isfile, join\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "\n",
        "from torchvision import transforms\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wok6VHuiP_NA"
      },
      "source": [
        "class BaseLine:\n",
        "    def __init__(self,\n",
        "        input_images_path_ = 'drive/My Drive/AML2020/images',\n",
        "        csv_ = 'drive/My Drive/AML2020/train.csv',\n",
        "        input_path_ = 'drive/My Drive/AML2020',\n",
        "        train_path_ = 'drive/My Drive/AML2020/train4',\n",
        "        test_path_ = 'drive/My Drive/AML2020/test',\n",
        "        valid_path_ = 'drive/My Drive/AML2020/validation',\n",
        "                no_=4):\n",
        "        \n",
        "        import torch\n",
        "        import torchvision\n",
        "        \n",
        "        self.input_images_path = input_images_path_\n",
        "        self.csv = csv_\n",
        "        \n",
        "        self.input_path = input_path_\n",
        "        self.train_path = train_path_\n",
        "        self.test_path = test_path_\n",
        "        self.valid_path = valid_path_\n",
        "        self.no=no_\n",
        "\n",
        "\n",
        "    \n",
        "    def folder_generator(self):\n",
        "        import pandas as pd\n",
        "        import logging as log\n",
        "        import os\n",
        "        \n",
        "        csv_labels = pd.read_csv(self.csv)\n",
        "        \n",
        "        #images_paths = list(csv_labels['file'])\n",
        "        images_paths = csv_labels['file']\n",
        "        images_paths = [path.replace('images/', '') for path in images_paths]\n",
        "        \n",
        "        #images_labels = list(csv_labels['is_tiger'])\n",
        "        images_labels = csv_labels['is_tiger']\n",
        "        counter = 1\n",
        "        \n",
        "        tiger_path_train = os.path.join(self.train_path, 'tiger')\n",
        "        tiger1_path_train = os.path.join(self.train_path, 'tiger1')\n",
        "        tiger2_path_train = os.path.join(self.train_path, 'tiger2')\n",
        "        tiger3_path_train = os.path.join(self.train_path, 'tiger3')\n",
        "        tiger4_path_train = os.path.join(self.train_path, 'tiger4')\n",
        "        not_tiger_path_train = os.path.join(self.train_path, 'not_tiger')\n",
        "\n",
        "        \n",
        "        tiger_path_val = os.path.join(self.valid_path, 'tiger')\n",
        "        not_tiger_path_val = os.path.join(self.valid_path, 'not_tiger')\n",
        "        \n",
        "        test_unknown_path = os.path.join(self.test_path, 'unknown')\n",
        "        \n",
        "        os.mkdir(self.train_path)\n",
        "        os.mkdir(tiger_path_train)\n",
        "        os.mkdir(not_tiger_path_train)\n",
        "\n",
        "        os.mkdir(self.valid_path)\n",
        "        os.mkdir(tiger_path_val)\n",
        "        os.mkdir(not_tiger_path_val)\n",
        "        \n",
        "        os.mkdir(self.test_path)\n",
        "        os.mkdir(test_unknown_path)\n",
        "        \n",
        "        #Handling Train Images\n",
        "        print('###Handling Train Images')\n",
        "        for image_name, image_label in zip(images_paths, images_labels):\n",
        "            print('Copying image: {}, with label: {}'.format(image_name, image_label))    \n",
        "            if image_name.split('_')[0] == 'train' and counter % 5 != 0:\n",
        "                if image_label == 1:\n",
        "                    source_dir = os.path.join(self.input_images_path, image_name) \n",
        "                    dest_dir = os.path.join(tiger_path_train, image_name)\n",
        "                    shutil.copy(source_dir, dest_dir)\n",
        "                    counter += 1\n",
        "                    print('Copied image: {} to {}'.format(image_name, tiger_path_train))\n",
        "                else:\n",
        "                    source_dir = os.path.join(self.input_images_path, image_name) \n",
        "                    dest_dir = os.path.join(not_tiger_path_train, image_name)\n",
        "                    shutil.copy(source_dir, dest_dir)\n",
        "                    counter += 1\n",
        "                    print('Copied image: {} to {}'.format(image_name, not_tiger_path_train))\n",
        "            else:\n",
        "                if image_label == 1:\n",
        "                    source_dir = os.path.join(self.input_images_path, image_name) \n",
        "                    dest_dir = os.path.join(tiger_path_val, image_name)\n",
        "                    shutil.copy(source_dir, dest_dir)\n",
        "                    counter += 1\n",
        "                    print('Copied image: {} to {}'.format(image_name, tiger_path_val))\n",
        "                else:\n",
        "                    source_dir = os.path.join(self.input_images_path, image_name) \n",
        "                    dest_dir = os.path.join(not_tiger_path_val, image_name)\n",
        "                    shutil.copy(source_dir, dest_dir)\n",
        "                    counter += 1\n",
        "                    print('Copied image: {} to {}'.format(image_name, not_tiger_path_val))\n",
        "            \n",
        "    \n",
        "    def data_loader(self):\n",
        "        import torch\n",
        "        import torchvision\n",
        "        from torchvision import transforms\n",
        "        #ImageFolder\n",
        "        #Augementation for train and valid images\n",
        "        train_transforms = transforms.Compose([\n",
        "            transforms.RandomResizedCrop(224),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "        ])\n",
        "\n",
        "        val_transforms = transforms.Compose([\n",
        "            transforms.Resize((224, 224)),\n",
        "            transforms.ToTensor(), \n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "        ])\n",
        "\n",
        "        train_dataset = torchvision.datasets.ImageFolder(self.train_path, train_transforms)\n",
        "        #train_dataset = torchvision.datasets.ImageFolder(train_data, train_transforms)\n",
        "        validation_dataset = torchvision.datasets.ImageFolder(self.valid_path, val_transforms)\n",
        "        \n",
        "        #DataLoader\n",
        "        batch_size = 16\n",
        "        train_dataloader = torch.utils.data.DataLoader(\n",
        "            train_dataset, batch_size=batch_size, shuffle=True, num_workers=batch_size\n",
        "        )\n",
        "\n",
        "        validation_dataloader = torch.utils.data.DataLoader(\n",
        "            validation_dataset, batch_size=batch_size, shuffle=True, num_workers=batch_size\n",
        "        )\n",
        "        print(len(train_dataset), len(validation_dataset))\n",
        "        print(len(train_dataloader), len(validation_dataloader))\n",
        "        return train_dataloader, validation_dataloader\n",
        "    \n",
        "    def show_images(self, train_dataloader):\n",
        "        import numpy as np\n",
        "        import matplotlib.pyplot as plt\n",
        "        X_batch, y_batch = next(iter(train_dataloader))\n",
        "        mean = np.array([0.485, 0.456, 0.406])\n",
        "        std = np.array([[0.229, 0.224, 0.225]])\n",
        "        for index in range(5):\n",
        "            plt.title(y_batch[index])\n",
        "            plt.imshow(X_batch[index].permute(1,2,0).numpy() * std + mean, )\n",
        "            plt.show()\n",
        "    \n",
        "    def model(self):\n",
        "        from torchvision import models\n",
        "        import torch\n",
        "        model = models.resnet152(pretrained=True)\n",
        "        \n",
        "        \n",
        "        #Disable grad for all conv layers\n",
        "        for param in model.parameters():\n",
        "            param.requires_grad = False \n",
        "\n",
        "        model.fc = torch.nn.Linear(model.fc.in_features, 2)\n",
        "        device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "        model.to(device)\n",
        "        loss = torch.nn.CrossEntropyLoss()\n",
        "        optimizer = torch.optim.Adam(model.parameters(),amsgrad=True, lr=3.0e-4)\n",
        "       \n",
        "        \n",
        "        #Declay LR by a factor of 0.1 every 5th epoch\n",
        "        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size = 5, gamma = 0.4)\n",
        "        return model, loss, optimizer, scheduler, device\n",
        "    \n",
        "    def train_model(self, model, loss, optimizer, scheduler, train, validation, device, num_epochs):\n",
        "        import torch\n",
        "        from tqdm import tqdm\n",
        "\n",
        "        best_accuracy=-1\n",
        "        best_path='best'+str(self.no)+'.pth'\n",
        "\n",
        "        for epoch in range(num_epochs):\n",
        "            print('Epoch {}/{}:'.format(epoch, num_epochs - 1), flush=True)\n",
        "\n",
        "            # Each epoch has a training and validation phase\n",
        "            for phase in ['train', 'val']:\n",
        "                if phase == 'train':\n",
        "                    dataloader = train\n",
        "                    scheduler.step()\n",
        "                    \n",
        "                    model.train()  # Set model to training mode\n",
        "                else:\n",
        "                    dataloader = validation\n",
        "                    model.eval()   # Set model to evaluate mode\n",
        "\n",
        "                running_loss = 0.\n",
        "                running_acc = 0.\n",
        "                running_acc_tiger = 0.\n",
        "                running_acc_not_tiger = 0.\n",
        "\n",
        "                # Iterate over data.\n",
        "                for inputs, labels in tqdm(dataloader):\n",
        "                    inputs = inputs.to(device)\n",
        "                    labels = labels.to(device)\n",
        "\n",
        "                    optimizer.zero_grad()\n",
        "\n",
        "                    # forward and backward\n",
        "                    with torch.set_grad_enabled(phase == 'train'):\n",
        "                        preds = model(inputs)\n",
        "                        loss_value = loss(preds, labels)\n",
        "                        preds_class = preds.argmax(dim=1)\n",
        "\n",
        "                        # backward + optimize only if in training phase\n",
        "                        if phase == 'train':\n",
        "                            loss_value.backward()\n",
        "                            optimizer.step()\n",
        "\n",
        "                    # statistics\n",
        "                    running_loss += loss_value.item()\n",
        "                    running_acc += (preds_class == labels.data).float().mean()\n",
        "                    running_acc_tiger += (preds_class == 1).float().mean()\n",
        "                    running_acc_not_tiger += (preds_class == 0).float().mean()\n",
        "\n",
        "                epoch_loss = running_loss / len(dataloader)\n",
        "                epoch_acc = running_acc / len(dataloader)\n",
        "                epoch_acc_tiger = running_acc_tiger / len(dataloader)\n",
        "                epoch_acc_not_tiger = running_acc_not_tiger / len(dataloader)\n",
        "\n",
        "\n",
        "\n",
        "                print('{} Loss: {:.4f} Acc: {:.4f} Tiger Acc: {:.4f} Not Tiger Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc, epoch_acc_tiger, epoch_acc_not_tiger), flush=True)\n",
        "\n",
        "                if epoch_acc>best_accuracy and phase=='val' :\n",
        "                    \n",
        "                    self.create_checkpoint(model,optimizer,best_path,epoch,loss_value)\n",
        "                    best_accuracy=epoch_acc\n",
        "        \n",
        "        \n",
        "        self.load_from_checkpoint(model,optimizer,best_path)\n",
        "\n",
        "        return model\n",
        "\n",
        "    def create_checkpoint(self,model,optimizer,path,epoch,loss):\n",
        "        \n",
        "        # basically copied from the tutorial, \n",
        "        # https://pytorch.org/tutorials/recipes/recipes/saving_and_loading_a_general_checkpoint.html\n",
        "\n",
        "        torch.save({\n",
        "              'epoch': epoch,\n",
        "              'model_state_dict': model.state_dict(),\n",
        "              'optimizer_state_dict': optimizer.state_dict(),\n",
        "              'loss': loss,\n",
        "              }, path)\n",
        "        \n",
        "    def load_from_checkpoint(self,model,optimizer,path):\n",
        "        \n",
        "        # basically copied from the tutorial, \n",
        "        # https://pytorch.org/tutorials/recipes/recipes/saving_and_loading_a_general_checkpoint.html\n",
        "        \n",
        "        checkpoint = torch.load(path)\n",
        "        model.load_state_dict(checkpoint['model_state_dict'])\n",
        "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "\n",
        "        print('reloading best model of epoch %d, loss %f'%(checkpoint['epoch'],checkpoint['loss']))\n",
        "\n",
        "    \n",
        "    def run(self,num_ep=10):\n",
        "        #Processing data\n",
        "        #Job = BaseLine()\n",
        "        #Job.folder_generator()\n",
        "        #train_dataloader, validation_dataloader = Job.data_loader('drive/My Drive/AML2020/train0')\n",
        "        #train_dataloader1, validation_dataloader1 = Job.data_loader('drive/My Drive/AML2020/train1')\n",
        "        #train_dataloader2, validation_dataloader2 = Job.data_loader('drive/My Drive/AML2020/train2')\n",
        "        #train_dataloader3, validation_dataloader3 = Job.data_loader('drive/My Drive/AML2020/train3')\n",
        "        #train_dataloader4, validation_dataloader4 = Job.data_loader('drive/My Drive/AML2020/train4')\n",
        "        #Job.show_images(train_dataloader)\n",
        "        \n",
        "        #Define model\n",
        "        #model, loss, optimizer, scheduler, device = Job.model()\n",
        "        #print(model, loss, optimizer, scheduler)\n",
        "        #Train model \n",
        "        #trained_model = Job.train_model(model, loss, optimizer, scheduler, train_dataloader, validation_dataloader, device, num_epochs=num_ep)\n",
        "        #trained_model1 = Job.train_model(model, loss, optimizer, scheduler, train_dataloader1, validation_dataloader1, device, num_epochs=num_ep)\n",
        "        #trained_model2 = Job.train_model(model, loss, optimizer, scheduler, train_dataloader2, validation_dataloader2, device, num_epochs=num_ep)\n",
        "        #trained_model3 = Job.train_model(model, loss, optimizer, scheduler, train_dataloader3, validation_dataloader3, device, num_epochs=num_ep)\n",
        "        #trained_model4 = Job.train_model(model, loss, optimizer, scheduler, train_dataloader4, validation_dataloader4, device, num_epochs=num_ep)\n",
        "        #return trained_model, trained_model1, trained_model2, trained_model3, trained_model4\n",
        "        #return trained_model\n",
        "\n",
        "\n",
        "\n",
        "        train_dataloader, validation_dataloader = self.data_loader()\n",
        "        \n",
        "        #Define model\n",
        "        \n",
        "        model, loss, optimizer, scheduler, device = self.model()\n",
        "\n",
        "        #Train model \n",
        "        \n",
        "        trained_model = self.train_model(model, loss, optimizer, scheduler, train_dataloader, validation_dataloader,\n",
        "                                         device, num_epochs=num_ep)\n",
        "        return trained_model"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bg57S9lzQmLw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4eb791f-1b71-4f95-8d2e-8bfce9236262"
      },
      "source": [
        "model = BaseLine().run()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1132 855\n",
            "71 54\n",
            "Epoch 0/9:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n",
            "100%|██████████| 71/71 [00:58<00:00,  1.21it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train Loss: 0.6156 Acc: 0.6831 Tiger Acc: 0.5062 Not Tiger Acc: 0.4938\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 54/54 [00:18<00:00,  2.92it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val Loss: 0.5766 Acc: 0.7108 Tiger Acc: 0.6081 Not Tiger Acc: 0.3919\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/9:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 71/71 [00:25<00:00,  2.79it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train Loss: 0.5166 Acc: 0.7755 Tiger Acc: 0.4886 Not Tiger Acc: 0.5114\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 54/54 [00:18<00:00,  2.90it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val Loss: 0.5053 Acc: 0.7667 Tiger Acc: 0.6564 Not Tiger Acc: 0.3436\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2/9:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 71/71 [00:25<00:00,  2.82it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train Loss: 0.4756 Acc: 0.7952 Tiger Acc: 0.5000 Not Tiger Acc: 0.5000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 54/54 [00:18<00:00,  2.89it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val Loss: 0.3986 Acc: 0.8391 Tiger Acc: 0.7497 Not Tiger Acc: 0.2503\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 3/9:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 71/71 [00:25<00:00,  2.80it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train Loss: 0.4435 Acc: 0.8216 Tiger Acc: 0.5065 Not Tiger Acc: 0.4935\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 54/54 [00:18<00:00,  2.86it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val Loss: 0.3050 Acc: 0.8839 Tiger Acc: 0.8307 Not Tiger Acc: 0.1693\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 4/9:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 71/71 [00:25<00:00,  2.76it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train Loss: 0.4327 Acc: 0.8242 Tiger Acc: 0.5062 Not Tiger Acc: 0.4938\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 54/54 [00:18<00:00,  2.93it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val Loss: 0.4037 Acc: 0.8376 Tiger Acc: 0.7227 Not Tiger Acc: 0.2773\n",
            "Epoch 5/9:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 71/71 [00:25<00:00,  2.79it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train Loss: 0.4149 Acc: 0.8260 Tiger Acc: 0.4827 Not Tiger Acc: 0.5173\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 54/54 [00:18<00:00,  2.92it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val Loss: 0.3421 Acc: 0.8585 Tiger Acc: 0.7806 Not Tiger Acc: 0.2194\n",
            "Epoch 6/9:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 71/71 [00:25<00:00,  2.80it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train Loss: 0.4259 Acc: 0.8154 Tiger Acc: 0.4924 Not Tiger Acc: 0.5076\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 54/54 [00:18<00:00,  2.90it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val Loss: 0.3164 Acc: 0.8715 Tiger Acc: 0.7951 Not Tiger Acc: 0.2049\n",
            "Epoch 7/9:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 71/71 [00:25<00:00,  2.78it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train Loss: 0.4214 Acc: 0.8046 Tiger Acc: 0.5270 Not Tiger Acc: 0.4730\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 54/54 [00:18<00:00,  2.90it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val Loss: 0.4156 Acc: 0.8133 Tiger Acc: 0.6900 Not Tiger Acc: 0.3100\n",
            "Epoch 8/9:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 71/71 [00:25<00:00,  2.77it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train Loss: 0.4051 Acc: 0.8072 Tiger Acc: 0.4792 Not Tiger Acc: 0.5208\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 54/54 [00:18<00:00,  2.86it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val Loss: 0.2849 Acc: 0.8839 Tiger Acc: 0.8153 Not Tiger Acc: 0.1847\n",
            "Epoch 9/9:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 71/71 [00:25<00:00,  2.81it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train Loss: 0.4103 Acc: 0.8257 Tiger Acc: 0.5103 Not Tiger Acc: 0.4897\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 54/54 [00:18<00:00,  2.92it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val Loss: 0.3590 Acc: 0.8449 Tiger Acc: 0.7384 Not Tiger Acc: 0.2616\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "reloading best model of epoch 3, loss 0.307121\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fw0XqoqKJ78P"
      },
      "source": [
        "def model_(n,basedir='drive/My Drive/AML2020/'):\n",
        "    \n",
        "    \n",
        "    \n",
        "    model=BaseLine(\n",
        "    train_path_=os.path.join(basedir,'train'+str(n)),\n",
        "    valid_path_=os.path.join(basedir,'validation'),\n",
        "    test_path_=os.path.join(basedir,'test'),\n",
        "    no_=n)\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YxBn4sbRKuc_",
        "outputId": "a82aac92-4191-4b1c-9743-8847d2e600f8"
      },
      "source": [
        "models={}\n",
        "for i in range(5):\n",
        "    m=model_(i)\n",
        "    trained_m=m.run(num_ep=0)\n",
        "    models[i]=trained_m"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1136 855\n",
            "71 54\n",
            "reloading best model of epoch 1, loss 0.385012\n",
            "1132 855\n",
            "71 54\n",
            "reloading best model of epoch 7, loss 0.528256\n",
            "1132 855\n",
            "71 54\n",
            "reloading best model of epoch 2, loss 0.369209\n",
            "1132 855\n",
            "71 54\n",
            "reloading best model of epoch 0, loss 0.374374\n",
            "1132 855\n",
            "71 54\n",
            "reloading best model of epoch 3, loss 0.307121\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2z5ixf4H6oD"
      },
      "source": [
        "import pandas as pd\n",
        "import pickle\n",
        "\n",
        "def softmax(tensor):\n",
        "    \n",
        "    z=np.sum(np.exp(np.asarray(tensor)))\n",
        "    \n",
        "    return np.exp(np.asarray(tensor))/z\n",
        "\n",
        "\n",
        "def confidency(preds):\n",
        "    \n",
        "    confidencies=[]\n",
        "    \n",
        "    for pic in range(preds.shape[0]):\n",
        "        \n",
        "        confidencies.append(softmax(preds[pic,:])[1]) # guess that this is the tiger probability\n",
        "        \n",
        "    return confidencies"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47rh7_nuIJZm"
      },
      "source": [
        "#test_tiger_names_all=os.listdir('drive/My Drive/AML2020/validation/tiger')\n",
        "test_other_names=os.listdir('drive/My Drive/AML2020/validation/not_tiger')\n",
        "test_tiger_names=random.sample(os.listdir('drive/My Drive/AML2020/validation/tiger'),len(test_other_names))\n",
        "\n",
        "batch_size=10\n",
        "counter=0\n",
        "to_batch=[]\n",
        "results={}\n",
        "\n",
        "val_transforms = transforms.Compose([\n",
        "            transforms.Resize((224, 224)),\n",
        "            transforms.ToTensor(), \n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "        ])\n",
        "\n",
        "for id_,model in models.items():\n",
        "    results[id_]={}\n",
        "    model.eval()\n",
        "\n",
        "for pic in test_other_names:\n",
        "    to_batch.append((pic,val_transforms(Image.open('drive/My Drive/AML2020/validation/not_tiger/'+pic))))\n",
        "    counter+=1\n",
        "    \n",
        "    if counter==batch_size:\n",
        "        \n",
        "        batch=torch.cat([(item[1].reshape(-1,3,224,224)).cuda() for item in to_batch ])\n",
        "        \n",
        "        for id_,model in models.items():\n",
        "            \n",
        "            conf=confidency(model(batch).cpu().detach().numpy())\n",
        "            \n",
        "            for idx,item in enumerate(to_batch):\n",
        "            \n",
        "                results[id_][item[0]]=conf[idx]\n",
        "                \n",
        "        counter=0\n",
        "        to_batch=[]\n",
        "        \n",
        "for pic in test_tiger_names:\n",
        "    to_batch.append((pic,val_transforms(Image.open('drive/My Drive/AML2020/validation/tiger/'+pic).convert('RGB'))))\n",
        "    counter+=1\n",
        "    \n",
        "    if counter==batch_size:\n",
        "        \n",
        "        batch=torch.cat([(item[1].reshape(-1,3,224,224)).cuda() for item in to_batch ])\n",
        "        \n",
        "        for id_,model in models.items():\n",
        "            \n",
        "            conf=confidency(model(batch).cpu().detach().numpy())\n",
        "            \n",
        "            for idx,item in enumerate(to_batch):\n",
        "            \n",
        "                results[id_][item[0]]=conf[idx]\n",
        "                \n",
        "        counter=0\n",
        "        to_batch=[]\n",
        "    \n",
        "            \n",
        "if len(to_batch)>0: #some pics remained unevaluated\n",
        "    \n",
        "    batch=torch.cat([(item[1].reshape(-1,3,224,224)).cuda() for item in to_batch ])\n",
        "        \n",
        "    for id_,model in models.items():\n",
        "\n",
        "        conf=confidency(model(batch).cpu().detach().numpy())\n",
        "\n",
        "        for idx,item in enumerate(to_batch):\n",
        "\n",
        "            results[id_][item[0]]=conf[idx]\n",
        "\n",
        "    counter=0\n",
        "    to_batch=[]"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xLDANh6VyTej"
      },
      "source": [
        "f=open('results_dictionary.txt','wb')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HBn6N29xz16x"
      },
      "source": [
        "pickle.dump(results,f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Wc_MiJ7z2OD"
      },
      "source": [
        "import copy"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JO0VDYAL0o8b"
      },
      "source": [
        "rr=copy.deepcopy(results)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xChE6Ebr0uap"
      },
      "source": [
        "for idx,model in models.items():\n",
        "    for key,value in rr[idx].items():\n",
        "        rr[idx][key]=list([value,])"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "id": "ZlIrjwXw03fM",
        "outputId": "5064ad8d-e160-4071-f366-c4d538622db7"
      },
      "source": [
        "pd.DataFrame.from_dict(rr[0])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>train_14.png</th>\n",
              "      <th>train_24.png</th>\n",
              "      <th>train_49.png</th>\n",
              "      <th>train_104.png</th>\n",
              "      <th>train_199.png</th>\n",
              "      <th>train_244.png</th>\n",
              "      <th>train_249.png</th>\n",
              "      <th>train_314.png</th>\n",
              "      <th>train_364.png</th>\n",
              "      <th>train_384.png</th>\n",
              "      <th>train_394.png</th>\n",
              "      <th>train_424.png</th>\n",
              "      <th>train_474.png</th>\n",
              "      <th>train_479.png</th>\n",
              "      <th>train_529.png</th>\n",
              "      <th>train_534.png</th>\n",
              "      <th>train_539.png</th>\n",
              "      <th>train_659.png</th>\n",
              "      <th>train_719.png</th>\n",
              "      <th>train_724.png</th>\n",
              "      <th>train_789.png</th>\n",
              "      <th>train_834.png</th>\n",
              "      <th>train_869.png</th>\n",
              "      <th>train_1004.png</th>\n",
              "      <th>train_1029.png</th>\n",
              "      <th>train_1034.png</th>\n",
              "      <th>train_1079.png</th>\n",
              "      <th>train_1084.png</th>\n",
              "      <th>train_1109.png</th>\n",
              "      <th>train_1124.png</th>\n",
              "      <th>train_1134.png</th>\n",
              "      <th>train_1139.png</th>\n",
              "      <th>train_1149.png</th>\n",
              "      <th>train_1179.png</th>\n",
              "      <th>train_1189.png</th>\n",
              "      <th>train_1229.png</th>\n",
              "      <th>train_1294.png</th>\n",
              "      <th>train_1299.png</th>\n",
              "      <th>train_1309.png</th>\n",
              "      <th>train_1339.png</th>\n",
              "      <th>...</th>\n",
              "      <th>train_419.png</th>\n",
              "      <th>train_2594.png</th>\n",
              "      <th>train_2889.png</th>\n",
              "      <th>train_2009.png</th>\n",
              "      <th>train_2384.png</th>\n",
              "      <th>train_1784.png</th>\n",
              "      <th>train_1424.png</th>\n",
              "      <th>train_4164.png</th>\n",
              "      <th>train_2369.png</th>\n",
              "      <th>train_2499.png</th>\n",
              "      <th>train_1819.png</th>\n",
              "      <th>train_2164.png</th>\n",
              "      <th>train_3914.png</th>\n",
              "      <th>train_1744.png</th>\n",
              "      <th>train_1944.png</th>\n",
              "      <th>train_2374.png</th>\n",
              "      <th>train_2729.png</th>\n",
              "      <th>train_4194.png</th>\n",
              "      <th>train_769.png</th>\n",
              "      <th>train_1369.png</th>\n",
              "      <th>train_2554.png</th>\n",
              "      <th>train_3554.png</th>\n",
              "      <th>train_509.png</th>\n",
              "      <th>train_574.png</th>\n",
              "      <th>train_2179.png</th>\n",
              "      <th>train_674.png</th>\n",
              "      <th>train_969.png</th>\n",
              "      <th>train_1409.png</th>\n",
              "      <th>train_64.png</th>\n",
              "      <th>train_2719.png</th>\n",
              "      <th>train_1874.png</th>\n",
              "      <th>train_1909.png</th>\n",
              "      <th>train_3864.png</th>\n",
              "      <th>train_2969.png</th>\n",
              "      <th>train_159.png</th>\n",
              "      <th>train_1484.png</th>\n",
              "      <th>train_2894.png</th>\n",
              "      <th>train_359.png</th>\n",
              "      <th>train_3154.png</th>\n",
              "      <th>train_2909.png</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.189143</td>\n",
              "      <td>0.279337</td>\n",
              "      <td>0.455895</td>\n",
              "      <td>0.650482</td>\n",
              "      <td>0.465951</td>\n",
              "      <td>0.274022</td>\n",
              "      <td>0.379819</td>\n",
              "      <td>0.729659</td>\n",
              "      <td>0.140439</td>\n",
              "      <td>0.28403</td>\n",
              "      <td>0.493719</td>\n",
              "      <td>0.665896</td>\n",
              "      <td>0.642337</td>\n",
              "      <td>0.625529</td>\n",
              "      <td>0.68902</td>\n",
              "      <td>0.369867</td>\n",
              "      <td>0.501832</td>\n",
              "      <td>0.375649</td>\n",
              "      <td>0.463684</td>\n",
              "      <td>0.522873</td>\n",
              "      <td>0.343321</td>\n",
              "      <td>0.534873</td>\n",
              "      <td>0.50459</td>\n",
              "      <td>0.504433</td>\n",
              "      <td>0.308487</td>\n",
              "      <td>0.441234</td>\n",
              "      <td>0.528905</td>\n",
              "      <td>0.564786</td>\n",
              "      <td>0.305978</td>\n",
              "      <td>0.372671</td>\n",
              "      <td>0.458445</td>\n",
              "      <td>0.366354</td>\n",
              "      <td>0.452228</td>\n",
              "      <td>0.319716</td>\n",
              "      <td>0.229278</td>\n",
              "      <td>0.757434</td>\n",
              "      <td>0.670347</td>\n",
              "      <td>0.809825</td>\n",
              "      <td>0.401043</td>\n",
              "      <td>0.811382</td>\n",
              "      <td>...</td>\n",
              "      <td>0.761076</td>\n",
              "      <td>0.658235</td>\n",
              "      <td>0.839415</td>\n",
              "      <td>0.417385</td>\n",
              "      <td>0.914986</td>\n",
              "      <td>0.687928</td>\n",
              "      <td>0.835009</td>\n",
              "      <td>0.732634</td>\n",
              "      <td>0.811377</td>\n",
              "      <td>0.755546</td>\n",
              "      <td>0.907806</td>\n",
              "      <td>0.797726</td>\n",
              "      <td>0.766613</td>\n",
              "      <td>0.762845</td>\n",
              "      <td>0.529694</td>\n",
              "      <td>0.881309</td>\n",
              "      <td>0.705178</td>\n",
              "      <td>0.852846</td>\n",
              "      <td>0.883161</td>\n",
              "      <td>0.850191</td>\n",
              "      <td>0.632148</td>\n",
              "      <td>0.85153</td>\n",
              "      <td>0.846878</td>\n",
              "      <td>0.596783</td>\n",
              "      <td>0.850114</td>\n",
              "      <td>0.70046</td>\n",
              "      <td>0.680678</td>\n",
              "      <td>0.862493</td>\n",
              "      <td>0.760404</td>\n",
              "      <td>0.696841</td>\n",
              "      <td>0.836076</td>\n",
              "      <td>0.836686</td>\n",
              "      <td>0.904015</td>\n",
              "      <td>0.932739</td>\n",
              "      <td>0.473777</td>\n",
              "      <td>0.708686</td>\n",
              "      <td>0.8034</td>\n",
              "      <td>0.778499</td>\n",
              "      <td>0.579354</td>\n",
              "      <td>0.477903</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1 rows × 272 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   train_14.png  train_24.png  ...  train_3154.png  train_2909.png\n",
              "0      0.189143      0.279337  ...        0.579354        0.477903\n",
              "\n",
              "[1 rows x 272 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0MsYN3it1DhB"
      },
      "source": [
        "tabular_res=pd.concat([pd.DataFrame.from_dict(rr[i]) for i in range(5)])"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "id": "X7-6GJhL1E59",
        "outputId": "fbac59f1-cc58-4849-e735-eb5c112461db"
      },
      "source": [
        "tabular_res"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>train_14.png</th>\n",
              "      <th>train_24.png</th>\n",
              "      <th>train_49.png</th>\n",
              "      <th>train_104.png</th>\n",
              "      <th>train_199.png</th>\n",
              "      <th>train_244.png</th>\n",
              "      <th>train_249.png</th>\n",
              "      <th>train_314.png</th>\n",
              "      <th>train_364.png</th>\n",
              "      <th>train_384.png</th>\n",
              "      <th>train_394.png</th>\n",
              "      <th>train_424.png</th>\n",
              "      <th>train_474.png</th>\n",
              "      <th>train_479.png</th>\n",
              "      <th>train_529.png</th>\n",
              "      <th>train_534.png</th>\n",
              "      <th>train_539.png</th>\n",
              "      <th>train_659.png</th>\n",
              "      <th>train_719.png</th>\n",
              "      <th>train_724.png</th>\n",
              "      <th>train_789.png</th>\n",
              "      <th>train_834.png</th>\n",
              "      <th>train_869.png</th>\n",
              "      <th>train_1004.png</th>\n",
              "      <th>train_1029.png</th>\n",
              "      <th>train_1034.png</th>\n",
              "      <th>train_1079.png</th>\n",
              "      <th>train_1084.png</th>\n",
              "      <th>train_1109.png</th>\n",
              "      <th>train_1124.png</th>\n",
              "      <th>train_1134.png</th>\n",
              "      <th>train_1139.png</th>\n",
              "      <th>train_1149.png</th>\n",
              "      <th>train_1179.png</th>\n",
              "      <th>train_1189.png</th>\n",
              "      <th>train_1229.png</th>\n",
              "      <th>train_1294.png</th>\n",
              "      <th>train_1299.png</th>\n",
              "      <th>train_1309.png</th>\n",
              "      <th>train_1339.png</th>\n",
              "      <th>...</th>\n",
              "      <th>train_419.png</th>\n",
              "      <th>train_2594.png</th>\n",
              "      <th>train_2889.png</th>\n",
              "      <th>train_2009.png</th>\n",
              "      <th>train_2384.png</th>\n",
              "      <th>train_1784.png</th>\n",
              "      <th>train_1424.png</th>\n",
              "      <th>train_4164.png</th>\n",
              "      <th>train_2369.png</th>\n",
              "      <th>train_2499.png</th>\n",
              "      <th>train_1819.png</th>\n",
              "      <th>train_2164.png</th>\n",
              "      <th>train_3914.png</th>\n",
              "      <th>train_1744.png</th>\n",
              "      <th>train_1944.png</th>\n",
              "      <th>train_2374.png</th>\n",
              "      <th>train_2729.png</th>\n",
              "      <th>train_4194.png</th>\n",
              "      <th>train_769.png</th>\n",
              "      <th>train_1369.png</th>\n",
              "      <th>train_2554.png</th>\n",
              "      <th>train_3554.png</th>\n",
              "      <th>train_509.png</th>\n",
              "      <th>train_574.png</th>\n",
              "      <th>train_2179.png</th>\n",
              "      <th>train_674.png</th>\n",
              "      <th>train_969.png</th>\n",
              "      <th>train_1409.png</th>\n",
              "      <th>train_64.png</th>\n",
              "      <th>train_2719.png</th>\n",
              "      <th>train_1874.png</th>\n",
              "      <th>train_1909.png</th>\n",
              "      <th>train_3864.png</th>\n",
              "      <th>train_2969.png</th>\n",
              "      <th>train_159.png</th>\n",
              "      <th>train_1484.png</th>\n",
              "      <th>train_2894.png</th>\n",
              "      <th>train_359.png</th>\n",
              "      <th>train_3154.png</th>\n",
              "      <th>train_2909.png</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.189143</td>\n",
              "      <td>0.279337</td>\n",
              "      <td>0.455895</td>\n",
              "      <td>0.650482</td>\n",
              "      <td>0.465951</td>\n",
              "      <td>0.274022</td>\n",
              "      <td>0.379819</td>\n",
              "      <td>0.729659</td>\n",
              "      <td>0.140439</td>\n",
              "      <td>0.284030</td>\n",
              "      <td>0.493719</td>\n",
              "      <td>0.665896</td>\n",
              "      <td>0.642337</td>\n",
              "      <td>0.625529</td>\n",
              "      <td>0.689020</td>\n",
              "      <td>0.369867</td>\n",
              "      <td>0.501832</td>\n",
              "      <td>0.375649</td>\n",
              "      <td>0.463684</td>\n",
              "      <td>0.522873</td>\n",
              "      <td>0.343321</td>\n",
              "      <td>0.534873</td>\n",
              "      <td>0.504590</td>\n",
              "      <td>0.504433</td>\n",
              "      <td>0.308487</td>\n",
              "      <td>0.441234</td>\n",
              "      <td>0.528905</td>\n",
              "      <td>0.564786</td>\n",
              "      <td>0.305978</td>\n",
              "      <td>0.372671</td>\n",
              "      <td>0.458445</td>\n",
              "      <td>0.366354</td>\n",
              "      <td>0.452228</td>\n",
              "      <td>0.319716</td>\n",
              "      <td>0.229278</td>\n",
              "      <td>0.757434</td>\n",
              "      <td>0.670347</td>\n",
              "      <td>0.809825</td>\n",
              "      <td>0.401043</td>\n",
              "      <td>0.811382</td>\n",
              "      <td>...</td>\n",
              "      <td>0.761076</td>\n",
              "      <td>0.658235</td>\n",
              "      <td>0.839415</td>\n",
              "      <td>0.417385</td>\n",
              "      <td>0.914986</td>\n",
              "      <td>0.687928</td>\n",
              "      <td>0.835009</td>\n",
              "      <td>0.732634</td>\n",
              "      <td>0.811377</td>\n",
              "      <td>0.755546</td>\n",
              "      <td>0.907806</td>\n",
              "      <td>0.797726</td>\n",
              "      <td>0.766613</td>\n",
              "      <td>0.762845</td>\n",
              "      <td>0.529694</td>\n",
              "      <td>0.881309</td>\n",
              "      <td>0.705178</td>\n",
              "      <td>0.852846</td>\n",
              "      <td>0.883161</td>\n",
              "      <td>0.850191</td>\n",
              "      <td>0.632148</td>\n",
              "      <td>0.851530</td>\n",
              "      <td>0.846878</td>\n",
              "      <td>0.596783</td>\n",
              "      <td>0.850114</td>\n",
              "      <td>0.700460</td>\n",
              "      <td>0.680678</td>\n",
              "      <td>0.862493</td>\n",
              "      <td>0.760404</td>\n",
              "      <td>0.696841</td>\n",
              "      <td>0.836076</td>\n",
              "      <td>0.836686</td>\n",
              "      <td>0.904015</td>\n",
              "      <td>0.932739</td>\n",
              "      <td>0.473777</td>\n",
              "      <td>0.708686</td>\n",
              "      <td>0.803400</td>\n",
              "      <td>0.778499</td>\n",
              "      <td>0.579354</td>\n",
              "      <td>0.477903</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.138299</td>\n",
              "      <td>0.127635</td>\n",
              "      <td>0.261170</td>\n",
              "      <td>0.696357</td>\n",
              "      <td>0.337087</td>\n",
              "      <td>0.093215</td>\n",
              "      <td>0.181282</td>\n",
              "      <td>0.464306</td>\n",
              "      <td>0.027251</td>\n",
              "      <td>0.275406</td>\n",
              "      <td>0.257741</td>\n",
              "      <td>0.550122</td>\n",
              "      <td>0.640194</td>\n",
              "      <td>0.408430</td>\n",
              "      <td>0.473288</td>\n",
              "      <td>0.155005</td>\n",
              "      <td>0.303061</td>\n",
              "      <td>0.256045</td>\n",
              "      <td>0.093730</td>\n",
              "      <td>0.307850</td>\n",
              "      <td>0.110436</td>\n",
              "      <td>0.180405</td>\n",
              "      <td>0.139455</td>\n",
              "      <td>0.343297</td>\n",
              "      <td>0.101206</td>\n",
              "      <td>0.265211</td>\n",
              "      <td>0.378100</td>\n",
              "      <td>0.390745</td>\n",
              "      <td>0.129853</td>\n",
              "      <td>0.132304</td>\n",
              "      <td>0.107687</td>\n",
              "      <td>0.218617</td>\n",
              "      <td>0.193863</td>\n",
              "      <td>0.148707</td>\n",
              "      <td>0.090165</td>\n",
              "      <td>0.595744</td>\n",
              "      <td>0.572215</td>\n",
              "      <td>0.721338</td>\n",
              "      <td>0.090201</td>\n",
              "      <td>0.866735</td>\n",
              "      <td>...</td>\n",
              "      <td>0.668902</td>\n",
              "      <td>0.641714</td>\n",
              "      <td>0.787556</td>\n",
              "      <td>0.136154</td>\n",
              "      <td>0.957643</td>\n",
              "      <td>0.698508</td>\n",
              "      <td>0.796842</td>\n",
              "      <td>0.688586</td>\n",
              "      <td>0.862848</td>\n",
              "      <td>0.725652</td>\n",
              "      <td>0.900382</td>\n",
              "      <td>0.667081</td>\n",
              "      <td>0.718473</td>\n",
              "      <td>0.719859</td>\n",
              "      <td>0.615679</td>\n",
              "      <td>0.893759</td>\n",
              "      <td>0.795890</td>\n",
              "      <td>0.849860</td>\n",
              "      <td>0.910889</td>\n",
              "      <td>0.922587</td>\n",
              "      <td>0.373165</td>\n",
              "      <td>0.870524</td>\n",
              "      <td>0.888507</td>\n",
              "      <td>0.679668</td>\n",
              "      <td>0.838592</td>\n",
              "      <td>0.765103</td>\n",
              "      <td>0.774970</td>\n",
              "      <td>0.955312</td>\n",
              "      <td>0.532469</td>\n",
              "      <td>0.711095</td>\n",
              "      <td>0.923860</td>\n",
              "      <td>0.777797</td>\n",
              "      <td>0.899869</td>\n",
              "      <td>0.944189</td>\n",
              "      <td>0.286446</td>\n",
              "      <td>0.690370</td>\n",
              "      <td>0.690259</td>\n",
              "      <td>0.588085</td>\n",
              "      <td>0.553543</td>\n",
              "      <td>0.376153</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.317500</td>\n",
              "      <td>0.235585</td>\n",
              "      <td>0.424287</td>\n",
              "      <td>0.727773</td>\n",
              "      <td>0.463125</td>\n",
              "      <td>0.284468</td>\n",
              "      <td>0.297921</td>\n",
              "      <td>0.798760</td>\n",
              "      <td>0.096799</td>\n",
              "      <td>0.491860</td>\n",
              "      <td>0.470004</td>\n",
              "      <td>0.697568</td>\n",
              "      <td>0.774993</td>\n",
              "      <td>0.614975</td>\n",
              "      <td>0.728544</td>\n",
              "      <td>0.296202</td>\n",
              "      <td>0.637427</td>\n",
              "      <td>0.412591</td>\n",
              "      <td>0.352165</td>\n",
              "      <td>0.552902</td>\n",
              "      <td>0.310436</td>\n",
              "      <td>0.381252</td>\n",
              "      <td>0.333288</td>\n",
              "      <td>0.561730</td>\n",
              "      <td>0.324300</td>\n",
              "      <td>0.569272</td>\n",
              "      <td>0.471802</td>\n",
              "      <td>0.640707</td>\n",
              "      <td>0.223668</td>\n",
              "      <td>0.408353</td>\n",
              "      <td>0.401747</td>\n",
              "      <td>0.450723</td>\n",
              "      <td>0.485660</td>\n",
              "      <td>0.333640</td>\n",
              "      <td>0.196175</td>\n",
              "      <td>0.696043</td>\n",
              "      <td>0.749678</td>\n",
              "      <td>0.778723</td>\n",
              "      <td>0.268129</td>\n",
              "      <td>0.796473</td>\n",
              "      <td>...</td>\n",
              "      <td>0.782212</td>\n",
              "      <td>0.802052</td>\n",
              "      <td>0.805049</td>\n",
              "      <td>0.512715</td>\n",
              "      <td>0.972262</td>\n",
              "      <td>0.587555</td>\n",
              "      <td>0.888862</td>\n",
              "      <td>0.703091</td>\n",
              "      <td>0.854911</td>\n",
              "      <td>0.811271</td>\n",
              "      <td>0.933043</td>\n",
              "      <td>0.767035</td>\n",
              "      <td>0.878093</td>\n",
              "      <td>0.825643</td>\n",
              "      <td>0.698824</td>\n",
              "      <td>0.935419</td>\n",
              "      <td>0.822490</td>\n",
              "      <td>0.888104</td>\n",
              "      <td>0.919234</td>\n",
              "      <td>0.896173</td>\n",
              "      <td>0.470344</td>\n",
              "      <td>0.872080</td>\n",
              "      <td>0.902690</td>\n",
              "      <td>0.749779</td>\n",
              "      <td>0.795172</td>\n",
              "      <td>0.840254</td>\n",
              "      <td>0.893439</td>\n",
              "      <td>0.930652</td>\n",
              "      <td>0.703833</td>\n",
              "      <td>0.700174</td>\n",
              "      <td>0.923598</td>\n",
              "      <td>0.806343</td>\n",
              "      <td>0.868608</td>\n",
              "      <td>0.965185</td>\n",
              "      <td>0.504121</td>\n",
              "      <td>0.843335</td>\n",
              "      <td>0.764314</td>\n",
              "      <td>0.689911</td>\n",
              "      <td>0.722713</td>\n",
              "      <td>0.650904</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.301530</td>\n",
              "      <td>0.376120</td>\n",
              "      <td>0.388266</td>\n",
              "      <td>0.659421</td>\n",
              "      <td>0.446457</td>\n",
              "      <td>0.444447</td>\n",
              "      <td>0.380817</td>\n",
              "      <td>0.571743</td>\n",
              "      <td>0.239923</td>\n",
              "      <td>0.509724</td>\n",
              "      <td>0.431737</td>\n",
              "      <td>0.575671</td>\n",
              "      <td>0.604188</td>\n",
              "      <td>0.467323</td>\n",
              "      <td>0.464156</td>\n",
              "      <td>0.545772</td>\n",
              "      <td>0.396334</td>\n",
              "      <td>0.364814</td>\n",
              "      <td>0.330145</td>\n",
              "      <td>0.355178</td>\n",
              "      <td>0.334651</td>\n",
              "      <td>0.519101</td>\n",
              "      <td>0.292177</td>\n",
              "      <td>0.457575</td>\n",
              "      <td>0.329341</td>\n",
              "      <td>0.505354</td>\n",
              "      <td>0.524687</td>\n",
              "      <td>0.565204</td>\n",
              "      <td>0.463305</td>\n",
              "      <td>0.374930</td>\n",
              "      <td>0.313013</td>\n",
              "      <td>0.478590</td>\n",
              "      <td>0.516653</td>\n",
              "      <td>0.454156</td>\n",
              "      <td>0.329865</td>\n",
              "      <td>0.683470</td>\n",
              "      <td>0.589945</td>\n",
              "      <td>0.554628</td>\n",
              "      <td>0.448344</td>\n",
              "      <td>0.750361</td>\n",
              "      <td>...</td>\n",
              "      <td>0.449684</td>\n",
              "      <td>0.576307</td>\n",
              "      <td>0.738930</td>\n",
              "      <td>0.518376</td>\n",
              "      <td>0.760002</td>\n",
              "      <td>0.614188</td>\n",
              "      <td>0.649442</td>\n",
              "      <td>0.577277</td>\n",
              "      <td>0.721576</td>\n",
              "      <td>0.536820</td>\n",
              "      <td>0.849268</td>\n",
              "      <td>0.669746</td>\n",
              "      <td>0.675361</td>\n",
              "      <td>0.505208</td>\n",
              "      <td>0.474583</td>\n",
              "      <td>0.697280</td>\n",
              "      <td>0.589663</td>\n",
              "      <td>0.786446</td>\n",
              "      <td>0.766576</td>\n",
              "      <td>0.793581</td>\n",
              "      <td>0.441958</td>\n",
              "      <td>0.749286</td>\n",
              "      <td>0.759415</td>\n",
              "      <td>0.549151</td>\n",
              "      <td>0.775707</td>\n",
              "      <td>0.624598</td>\n",
              "      <td>0.641722</td>\n",
              "      <td>0.814933</td>\n",
              "      <td>0.511703</td>\n",
              "      <td>0.563762</td>\n",
              "      <td>0.707680</td>\n",
              "      <td>0.776753</td>\n",
              "      <td>0.805047</td>\n",
              "      <td>0.867662</td>\n",
              "      <td>0.523264</td>\n",
              "      <td>0.510798</td>\n",
              "      <td>0.720596</td>\n",
              "      <td>0.582505</td>\n",
              "      <td>0.549355</td>\n",
              "      <td>0.571182</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.106305</td>\n",
              "      <td>0.180332</td>\n",
              "      <td>0.376707</td>\n",
              "      <td>0.638952</td>\n",
              "      <td>0.402865</td>\n",
              "      <td>0.214347</td>\n",
              "      <td>0.178054</td>\n",
              "      <td>0.686619</td>\n",
              "      <td>0.059674</td>\n",
              "      <td>0.343693</td>\n",
              "      <td>0.369970</td>\n",
              "      <td>0.707838</td>\n",
              "      <td>0.638626</td>\n",
              "      <td>0.606399</td>\n",
              "      <td>0.787147</td>\n",
              "      <td>0.167914</td>\n",
              "      <td>0.348978</td>\n",
              "      <td>0.256664</td>\n",
              "      <td>0.296144</td>\n",
              "      <td>0.326212</td>\n",
              "      <td>0.149031</td>\n",
              "      <td>0.298762</td>\n",
              "      <td>0.217925</td>\n",
              "      <td>0.584398</td>\n",
              "      <td>0.114124</td>\n",
              "      <td>0.284742</td>\n",
              "      <td>0.479793</td>\n",
              "      <td>0.487268</td>\n",
              "      <td>0.230539</td>\n",
              "      <td>0.179500</td>\n",
              "      <td>0.274199</td>\n",
              "      <td>0.301695</td>\n",
              "      <td>0.308601</td>\n",
              "      <td>0.150465</td>\n",
              "      <td>0.152376</td>\n",
              "      <td>0.762796</td>\n",
              "      <td>0.735264</td>\n",
              "      <td>0.788805</td>\n",
              "      <td>0.194855</td>\n",
              "      <td>0.779337</td>\n",
              "      <td>...</td>\n",
              "      <td>0.684021</td>\n",
              "      <td>0.777061</td>\n",
              "      <td>0.863807</td>\n",
              "      <td>0.201981</td>\n",
              "      <td>0.962924</td>\n",
              "      <td>0.748836</td>\n",
              "      <td>0.892308</td>\n",
              "      <td>0.565459</td>\n",
              "      <td>0.882286</td>\n",
              "      <td>0.758130</td>\n",
              "      <td>0.917311</td>\n",
              "      <td>0.813294</td>\n",
              "      <td>0.772862</td>\n",
              "      <td>0.840531</td>\n",
              "      <td>0.773548</td>\n",
              "      <td>0.913646</td>\n",
              "      <td>0.810060</td>\n",
              "      <td>0.702547</td>\n",
              "      <td>0.861600</td>\n",
              "      <td>0.833978</td>\n",
              "      <td>0.523497</td>\n",
              "      <td>0.923677</td>\n",
              "      <td>0.915845</td>\n",
              "      <td>0.625946</td>\n",
              "      <td>0.789246</td>\n",
              "      <td>0.658777</td>\n",
              "      <td>0.795072</td>\n",
              "      <td>0.926044</td>\n",
              "      <td>0.820374</td>\n",
              "      <td>0.669796</td>\n",
              "      <td>0.887371</td>\n",
              "      <td>0.821185</td>\n",
              "      <td>0.876719</td>\n",
              "      <td>0.968368</td>\n",
              "      <td>0.257208</td>\n",
              "      <td>0.546845</td>\n",
              "      <td>0.857603</td>\n",
              "      <td>0.666590</td>\n",
              "      <td>0.732240</td>\n",
              "      <td>0.537728</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 272 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   train_14.png  train_24.png  ...  train_3154.png  train_2909.png\n",
              "0      0.189143      0.279337  ...        0.579354        0.477903\n",
              "0      0.138299      0.127635  ...        0.553543        0.376153\n",
              "0      0.317500      0.235585  ...        0.722713        0.650904\n",
              "0      0.301530      0.376120  ...        0.549355        0.571182\n",
              "0      0.106305      0.180332  ...        0.732240        0.537728\n",
              "\n",
              "[5 rows x 272 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "RaaRIZns1Qec",
        "outputId": "c4ca1f6d-489c-4420-9ae0-344953608af2"
      },
      "source": [
        "tabular_res.index=[0,1,2,3,4]\n",
        "data=tabular_res.transpose()\n",
        "data.head()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>train_14.png</th>\n",
              "      <td>0.189143</td>\n",
              "      <td>0.138299</td>\n",
              "      <td>0.317500</td>\n",
              "      <td>0.301530</td>\n",
              "      <td>0.106305</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>train_24.png</th>\n",
              "      <td>0.279337</td>\n",
              "      <td>0.127635</td>\n",
              "      <td>0.235585</td>\n",
              "      <td>0.376120</td>\n",
              "      <td>0.180332</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>train_49.png</th>\n",
              "      <td>0.455895</td>\n",
              "      <td>0.261170</td>\n",
              "      <td>0.424287</td>\n",
              "      <td>0.388266</td>\n",
              "      <td>0.376707</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>train_104.png</th>\n",
              "      <td>0.650482</td>\n",
              "      <td>0.696357</td>\n",
              "      <td>0.727773</td>\n",
              "      <td>0.659421</td>\n",
              "      <td>0.638952</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>train_199.png</th>\n",
              "      <td>0.465951</td>\n",
              "      <td>0.337087</td>\n",
              "      <td>0.463125</td>\n",
              "      <td>0.446457</td>\n",
              "      <td>0.402865</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                      0         1         2         3         4\n",
              "train_14.png   0.189143  0.138299  0.317500  0.301530  0.106305\n",
              "train_24.png   0.279337  0.127635  0.235585  0.376120  0.180332\n",
              "train_49.png   0.455895  0.261170  0.424287  0.388266  0.376707\n",
              "train_104.png  0.650482  0.696357  0.727773  0.659421  0.638952\n",
              "train_199.png  0.465951  0.337087  0.463125  0.446457  0.402865"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lIdjblZnyjk8"
      },
      "source": [
        "labels = pd.read_csv('drive/My Drive/AML2020/train.csv')\n",
        "indeces = []\n",
        "for pic in list(data.index):\n",
        "    index = list(labels['file']).index('images/'+pic)\n",
        "    indeces.append(index)\n",
        "\n",
        "labels_data = labels.iloc[indeces]\n",
        "data['labels'] = list(labels_data['is_tiger'])"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "3y6rpaK93JaY",
        "outputId": "3fab9d6b-e373-412e-ace1-ad81a4cfd2ff"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>train_14.png</th>\n",
              "      <td>0.189143</td>\n",
              "      <td>0.138299</td>\n",
              "      <td>0.317500</td>\n",
              "      <td>0.301530</td>\n",
              "      <td>0.106305</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>train_24.png</th>\n",
              "      <td>0.279337</td>\n",
              "      <td>0.127635</td>\n",
              "      <td>0.235585</td>\n",
              "      <td>0.376120</td>\n",
              "      <td>0.180332</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>train_49.png</th>\n",
              "      <td>0.455895</td>\n",
              "      <td>0.261170</td>\n",
              "      <td>0.424287</td>\n",
              "      <td>0.388266</td>\n",
              "      <td>0.376707</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>train_104.png</th>\n",
              "      <td>0.650482</td>\n",
              "      <td>0.696357</td>\n",
              "      <td>0.727773</td>\n",
              "      <td>0.659421</td>\n",
              "      <td>0.638952</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>train_199.png</th>\n",
              "      <td>0.465951</td>\n",
              "      <td>0.337087</td>\n",
              "      <td>0.463125</td>\n",
              "      <td>0.446457</td>\n",
              "      <td>0.402865</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                      0         1         2         3         4  labels\n",
              "train_14.png   0.189143  0.138299  0.317500  0.301530  0.106305       0\n",
              "train_24.png   0.279337  0.127635  0.235585  0.376120  0.180332       0\n",
              "train_49.png   0.455895  0.261170  0.424287  0.388266  0.376707       0\n",
              "train_104.png  0.650482  0.696357  0.727773  0.659421  0.638952       0\n",
              "train_199.png  0.465951  0.337087  0.463125  0.446457  0.402865       0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BHEUp1gp303-"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import tree\n",
        "from sklearn import svm\n",
        "X, y = data[[0,1,2,3,4]], data['labels'] \n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
        "clf = LogisticRegression(random_state=0).fit(X_train,y_train)\n",
        "clf2 = svm.SVC().fit(X_train,y_train)\n",
        "clf3 = tree.DecisionTreeClassifier().fit(X_train,y_train)"
      ],
      "execution_count": 159,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IaqocLxfrn3p"
      },
      "source": [
        "a0_train = np.reshape(X_train[0].to_numpy(),(-1,1))\n",
        "a0_test = np.reshape(X_test[0].to_numpy(),(-1,1))\n",
        "clf_0 = tree.DecisionTreeClassifier().fit(a0_train,y_train)\n",
        "X_test['dt0'] = clf_0.predict(a0_test)\n",
        "a1_train = np.reshape(X_train[1].to_numpy(),(-1,1))\n",
        "a1_test = np.reshape(X_test[1].to_numpy(),(-1,1))\n",
        "clf_1 = tree.DecisionTreeClassifier().fit(a1_train,y_train)\n",
        "X_test['dt1'] = clf_1.predict(a1_test)\n",
        "a2_train = np.reshape(X_train[2].to_numpy(),(-1,1))\n",
        "a2_test = np.reshape(X_test[2].to_numpy(),(-1,1))\n",
        "clf_2 = tree.DecisionTreeClassifier().fit(a2_train,y_train)\n",
        "X_test['dt2'] = clf_2.predict(a2_test)\n",
        "a3_train = np.reshape(X_train[3].to_numpy(),(-1,1))\n",
        "a3_test = np.reshape(X_test[3].to_numpy(),(-1,1))\n",
        "clf_3 = tree.DecisionTreeClassifier().fit(a3_train,y_train)\n",
        "X_test['dt3'] = clf_3.predict(a3_test)\n",
        "a4_train = np.reshape(X_train[4].to_numpy(),(-1,1))\n",
        "a4_test = np.reshape(X_test[4].to_numpy(),(-1,1))\n",
        "clf_4 = tree.DecisionTreeClassifier().fit(a4_train,y_train)\n",
        "X_test['dt4'] = clf_4.predict(a4_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQxgMn-Gy5Jw"
      },
      "source": [
        "X_test['MV'] = round((X_test['dt0']+X_test['dt1']+X_test['dt2']+X_test['dt3']+X_test['dt4'])/5)\n",
        "\n",
        " "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zt1jm0acxggw",
        "outputId": "a3974dfd-4499-4c7a-d7df-227f3b869186"
      },
      "source": [
        "mv_acc = sum(1 for x,y in zip(X_test['MV'],y_test) if x == y) / len(y_test)\n",
        "mv_acc_tiger = sum(1 for x,y in zip(X_test['MV'],y_test) if x == 1 == y ) / sum(y_test)\n",
        "mv_acc_not_tiger = sum(1 for x,y in zip(X_test['MV'],y_test) if x == 0 == y) / (len(y_test) - sum(y_test))\n",
        "print(mv_acc, mv_acc_tiger, mv_acc_not_tiger)"
      ],
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8111111111111111 0.8048780487804879 0.8163265306122449\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P12ZhR4o646x"
      },
      "source": [
        "weights_tiger=[]\n",
        "weights_not_tiger=[]\n",
        "#for i in range(len(data)):\n",
        "  #if data['labels'][i] == 1:\n",
        "    #weights_not_tiger.append(0)\n",
        "    #weights_tiger.append(1/(sum(data['labels'])))\n",
        "  #else:\n",
        "    #weights_not_tiger.append(1/(len(data) - sum(data['labels'])))\n",
        "    #weights_tiger.append(0)\n",
        "for i in range(len(X_test)):\n",
        "  if y_test[i] == 1:\n",
        "    weights_not_tiger.append(0)\n",
        "    weights_tiger.append(1/(sum(y_test)))\n",
        "  else:\n",
        "    weights_not_tiger.append(1/(len(X_test) - sum(y_test)))\n",
        "    weights_tiger.append(0)\n"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fc7XLje1A-q5"
      },
      "source": [
        "Logistic regression accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JCcGX9TX7bfG",
        "outputId": "db71565d-fa38-40ff-c26d-c54645a2605c"
      },
      "source": [
        "print('Overall accuracy: {:.4f} Not Tiger accuracy: {:.4f} Tiger accuracy: {:.4f}'.format(clf.score(X_test,y_test),clf.score(X_test,y_test,sample_weight=weights_not_tiger),clf.score(X_test,y_test,sample_weight=weights_tiger)))"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overall accuracy: 0.8778 Not Tiger accuracy: 0.8571 Tiger accuracy: 0.9024\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O5eRgDhhBBTk"
      },
      "source": [
        "SVM accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mAnAuNJk-peR",
        "outputId": "14648329-32b6-472f-f256-1988e09f8e39"
      },
      "source": [
        "print('Overall accuracy: {:.4f} Not Tiger accuracy: {:.4f} Tiger accuracy: {:.4f}'.format(clf2.score(X_test,y_test),clf2.score(X_test,y_test,sample_weight=weights_not_tiger),clf2.score(X_test,y_test,sample_weight=weights_tiger)))"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overall accuracy: 0.8667 Not Tiger accuracy: 0.8980 Tiger accuracy: 0.8293\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ITfnHp3C3kqY"
      },
      "source": [
        "X, y = data[[0,1,2,3,4]], data['labels'] \n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
        "clf = LogisticRegression(random_state=0).fit(X_train,y_train)\n",
        "clf2 = svm.SVC().fit(X_train,y_train)\n",
        "clf3 = tree.DecisionTreeClassifier().fit(X_train,y_train)"
      ],
      "execution_count": 166,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "id": "8jAWM62qWolx",
        "outputId": "6e108cfe-53c1-4dbf-f996-a7e5aae05a90"
      },
      "source": [
        "results = pd.DataFrame()\n",
        "results['Overall Accuracy'] = [clf.score(X_test,y_test),clf2.score(X_test,y_test),clf3.score(X_test,y_test),mv_acc]\n",
        "results['Tiger Accuracy'] = [clf.score(X_test,y_test,sample_weight=weights_tiger),clf2.score(X_test,y_test,sample_weight=weights_tiger),clf3.score(X_test,y_test,sample_weight=weights_tiger),mv_acc_tiger]\n",
        "results['Non-tiger Accuracy'] = [clf.score(X_test,y_test,sample_weight=weights_not_tiger),clf2.score(X_test,y_test,sample_weight=weights_not_tiger),clf3.score(X_test,y_test,sample_weight=weights_not_tiger),mv_acc_not_tiger]\n",
        "results.index = ['LogReg','SVM','DT','Majority']\n",
        "results"
      ],
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Overall Accuracy</th>\n",
              "      <th>Tiger Accuracy</th>\n",
              "      <th>Non-tiger Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>LogReg</th>\n",
              "      <td>0.877778</td>\n",
              "      <td>0.902439</td>\n",
              "      <td>0.857143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SVM</th>\n",
              "      <td>0.866667</td>\n",
              "      <td>0.829268</td>\n",
              "      <td>0.897959</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DT</th>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.902439</td>\n",
              "      <td>0.775510</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Majority</th>\n",
              "      <td>0.811111</td>\n",
              "      <td>0.804878</td>\n",
              "      <td>0.816327</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          Overall Accuracy  Tiger Accuracy  Non-tiger Accuracy\n",
              "LogReg            0.877778        0.902439            0.857143\n",
              "SVM               0.866667        0.829268            0.897959\n",
              "DT                0.833333        0.902439            0.775510\n",
              "Majority          0.811111        0.804878            0.816327"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 167
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 553
        },
        "id": "i3Q6Un2YV7U2",
        "outputId": "a2622649-83b6-4e5a-de0f-6ba33aa391b0"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "labels = results.index\n",
        "\n",
        "\n",
        "x = np.arange(len(labels))  # the label locations\n",
        "width = 0.2  # the width of the bars\n",
        "fig, ax = plt.subplots(figsize=(18,9))\n",
        "rects1 = ax.bar(x - 1.1*width, results['Overall Accuracy'], width, label='Overall')\n",
        "rects2 = ax.bar(x, results['Tiger Accuracy'], width, label='Tiger')\n",
        "rects3 = ax.bar(x + 1.1*width, results['Non-tiger Accuracy'], width, label='Non-tiger')\n",
        "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
        "ax.set_ylabel('Accuracy')\n",
        "ax.set_title('Regression on the 5D data')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(labels)\n",
        "ax.legend()\n",
        "plt.show()"
      ],
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1296x648 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}