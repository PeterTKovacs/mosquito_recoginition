{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "APRO_baseline.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1IvBk--BwvvRi5mDSTYHS2iE0uS4C-UR1",
      "authorship_tag": "ABX9TyMOtAUEeSTFg+vUvA9IMh7W",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PeterTKovacs/mosquito_recoginition/blob/main/APRO_baseline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3yzkjbDcPSjY"
      },
      "source": [
        "from PIL import Image\n",
        "from pathlib import Path\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import shutil\n",
        "import os\n",
        "from os.path import isfile, join\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "\n",
        "from torchvision import transforms\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wok6VHuiP_NA"
      },
      "source": [
        "class BaseLine:\n",
        "    def __init__(self,\n",
        "        input_images_path_ = 'drive/My Drive/AML2020/images',\n",
        "        csv_ = 'drive/My Drive/AML2020/train.csv',\n",
        "        input_path_ = 'drive/My Drive/AML2020',\n",
        "        train_path_ = 'drive/My Drive/AML2020/train4',\n",
        "        test_path_ = 'drive/My Drive/AML2020/test',\n",
        "        valid_path_ = 'drive/My Drive/AML2020/validation',\n",
        "                no_=4):\n",
        "        \n",
        "        import torch\n",
        "        import torchvision\n",
        "        \n",
        "        self.input_images_path = input_images_path_\n",
        "        self.csv = csv_\n",
        "        \n",
        "        self.input_path = input_path_\n",
        "        self.train_path = train_path_\n",
        "        self.test_path = test_path_\n",
        "        self.valid_path = valid_path_\n",
        "        self.no=no_\n",
        "\n",
        "\n",
        "    \n",
        "    def folder_generator(self):\n",
        "        import pandas as pd\n",
        "        import logging as log\n",
        "        import os\n",
        "        \n",
        "        csv_labels = pd.read_csv(self.csv)\n",
        "        \n",
        "        #images_paths = list(csv_labels['file'])\n",
        "        images_paths = csv_labels['file']\n",
        "        images_paths = [path.replace('images/', '') for path in images_paths]\n",
        "        \n",
        "        #images_labels = list(csv_labels['is_tiger'])\n",
        "        images_labels = csv_labels['is_tiger']\n",
        "        counter = 1\n",
        "        \n",
        "        tiger_path_train = os.path.join(self.train_path, 'tiger')\n",
        "        tiger1_path_train = os.path.join(self.train_path, 'tiger1')\n",
        "        tiger2_path_train = os.path.join(self.train_path, 'tiger2')\n",
        "        tiger3_path_train = os.path.join(self.train_path, 'tiger3')\n",
        "        tiger4_path_train = os.path.join(self.train_path, 'tiger4')\n",
        "        not_tiger_path_train = os.path.join(self.train_path, 'not_tiger')\n",
        "\n",
        "        \n",
        "        tiger_path_val = os.path.join(self.valid_path, 'tiger')\n",
        "        not_tiger_path_val = os.path.join(self.valid_path, 'not_tiger')\n",
        "        \n",
        "        test_unknown_path = os.path.join(self.test_path, 'unknown')\n",
        "        \n",
        "        os.mkdir(self.train_path)\n",
        "        os.mkdir(tiger_path_train)\n",
        "        os.mkdir(not_tiger_path_train)\n",
        "\n",
        "        os.mkdir(self.valid_path)\n",
        "        os.mkdir(tiger_path_val)\n",
        "        os.mkdir(not_tiger_path_val)\n",
        "        \n",
        "        os.mkdir(self.test_path)\n",
        "        os.mkdir(test_unknown_path)\n",
        "        \n",
        "        #Handling Train Images\n",
        "        print('###Handling Train Images')\n",
        "        for image_name, image_label in zip(images_paths, images_labels):\n",
        "            print('Copying image: {}, with label: {}'.format(image_name, image_label))    \n",
        "            if image_name.split('_')[0] == 'train' and counter % 5 != 0:\n",
        "                if image_label == 1:\n",
        "                    source_dir = os.path.join(self.input_images_path, image_name) \n",
        "                    dest_dir = os.path.join(tiger_path_train, image_name)\n",
        "                    shutil.copy(source_dir, dest_dir)\n",
        "                    counter += 1\n",
        "                    print('Copied image: {} to {}'.format(image_name, tiger_path_train))\n",
        "                else:\n",
        "                    source_dir = os.path.join(self.input_images_path, image_name) \n",
        "                    dest_dir = os.path.join(not_tiger_path_train, image_name)\n",
        "                    shutil.copy(source_dir, dest_dir)\n",
        "                    counter += 1\n",
        "                    print('Copied image: {} to {}'.format(image_name, not_tiger_path_train))\n",
        "            else:\n",
        "                if image_label == 1:\n",
        "                    source_dir = os.path.join(self.input_images_path, image_name) \n",
        "                    dest_dir = os.path.join(tiger_path_val, image_name)\n",
        "                    shutil.copy(source_dir, dest_dir)\n",
        "                    counter += 1\n",
        "                    print('Copied image: {} to {}'.format(image_name, tiger_path_val))\n",
        "                else:\n",
        "                    source_dir = os.path.join(self.input_images_path, image_name) \n",
        "                    dest_dir = os.path.join(not_tiger_path_val, image_name)\n",
        "                    shutil.copy(source_dir, dest_dir)\n",
        "                    counter += 1\n",
        "                    print('Copied image: {} to {}'.format(image_name, not_tiger_path_val))\n",
        "            \n",
        "    \n",
        "    def data_loader(self):\n",
        "        import torch\n",
        "        import torchvision\n",
        "        from torchvision import transforms\n",
        "        #ImageFolder\n",
        "        #Augementation for train and valid images\n",
        "        train_transforms = transforms.Compose([\n",
        "            transforms.RandomResizedCrop(224),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "        ])\n",
        "\n",
        "        val_transforms = transforms.Compose([\n",
        "            transforms.Resize((224, 224)),\n",
        "            transforms.ToTensor(), \n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "        ])\n",
        "\n",
        "        train_dataset = torchvision.datasets.ImageFolder(self.train_path, train_transforms)\n",
        "        #train_dataset = torchvision.datasets.ImageFolder(train_data, train_transforms)\n",
        "        validation_dataset = torchvision.datasets.ImageFolder(self.valid_path, val_transforms)\n",
        "        \n",
        "        #DataLoader\n",
        "        batch_size = 16\n",
        "        train_dataloader = torch.utils.data.DataLoader(\n",
        "            train_dataset, batch_size=batch_size, shuffle=True, num_workers=batch_size\n",
        "        )\n",
        "\n",
        "        validation_dataloader = torch.utils.data.DataLoader(\n",
        "            validation_dataset, batch_size=batch_size, shuffle=True, num_workers=batch_size\n",
        "        )\n",
        "        print(len(train_dataset), len(validation_dataset))\n",
        "        print(len(train_dataloader), len(validation_dataloader))\n",
        "        return train_dataloader, validation_dataloader\n",
        "    \n",
        "    def show_images(self, train_dataloader):\n",
        "        import numpy as np\n",
        "        import matplotlib.pyplot as plt\n",
        "        X_batch, y_batch = next(iter(train_dataloader))\n",
        "        mean = np.array([0.485, 0.456, 0.406])\n",
        "        std = np.array([[0.229, 0.224, 0.225]])\n",
        "        for index in range(5):\n",
        "            plt.title(y_batch[index])\n",
        "            plt.imshow(X_batch[index].permute(1,2,0).numpy() * std + mean, )\n",
        "            plt.show()\n",
        "    \n",
        "    def model(self):\n",
        "        from torchvision import models\n",
        "        import torch\n",
        "        model = models.resnet152(pretrained=True)\n",
        "        \n",
        "        \n",
        "        #Disable grad for all conv layers\n",
        "        for param in model.parameters():\n",
        "            param.requires_grad = False \n",
        "\n",
        "        model.fc = torch.nn.Linear(model.fc.in_features, 2)\n",
        "        device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "        model.to(device)\n",
        "        loss = torch.nn.CrossEntropyLoss()\n",
        "        optimizer = torch.optim.Adam(model.parameters(),amsgrad=True, lr=3.0e-4)\n",
        "       \n",
        "        \n",
        "        #Declay LR by a factor of 0.1 every 5th epoch\n",
        "        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size = 5, gamma = 0.4)\n",
        "        return model, loss, optimizer, scheduler, device\n",
        "    \n",
        "    def train_model(self, model, loss, optimizer, scheduler, train, validation, device, num_epochs):\n",
        "        import torch\n",
        "        from tqdm import tqdm\n",
        "\n",
        "        best_accuracy=-1\n",
        "        best_path='best'+str(self.no)+'.pth'\n",
        "\n",
        "        for epoch in range(num_epochs):\n",
        "            print('Epoch {}/{}:'.format(epoch, num_epochs - 1), flush=True)\n",
        "\n",
        "            # Each epoch has a training and validation phase\n",
        "            for phase in ['train', 'val']:\n",
        "                if phase == 'train':\n",
        "                    dataloader = train\n",
        "                    scheduler.step()\n",
        "                    \n",
        "                    model.train()  # Set model to training mode\n",
        "                else:\n",
        "                    dataloader = validation\n",
        "                    model.eval()   # Set model to evaluate mode\n",
        "\n",
        "                running_loss = 0.\n",
        "                running_acc = 0.\n",
        "                running_acc_tiger = 0.\n",
        "                running_acc_not_tiger = 0.\n",
        "\n",
        "                # Iterate over data.\n",
        "                for inputs, labels in tqdm(dataloader):\n",
        "                    inputs = inputs.to(device)\n",
        "                    labels = labels.to(device)\n",
        "\n",
        "                    optimizer.zero_grad()\n",
        "\n",
        "                    # forward and backward\n",
        "                    with torch.set_grad_enabled(phase == 'train'):\n",
        "                        preds = model(inputs)\n",
        "                        loss_value = loss(preds, labels)\n",
        "                        preds_class = preds.argmax(dim=1)\n",
        "\n",
        "                        # backward + optimize only if in training phase\n",
        "                        if phase == 'train':\n",
        "                            loss_value.backward()\n",
        "                            optimizer.step()\n",
        "\n",
        "                    # statistics\n",
        "                    running_loss += loss_value.item()\n",
        "                    running_acc += (preds_class == labels.data).float().mean()\n",
        "                    running_acc_tiger += (preds_class == 1).float().mean()\n",
        "                    running_acc_not_tiger += (preds_class == 0).float().mean()\n",
        "\n",
        "                epoch_loss = running_loss / len(dataloader)\n",
        "                epoch_acc = running_acc / len(dataloader)\n",
        "                epoch_acc_tiger = running_acc_tiger / len(dataloader)\n",
        "                epoch_acc_not_tiger = running_acc_not_tiger / len(dataloader)\n",
        "\n",
        "\n",
        "\n",
        "                print('{} Loss: {:.4f} Acc: {:.4f} Tiger Acc: {:.4f} Not Tiger Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc, epoch_acc_tiger, epoch_acc_not_tiger), flush=True)\n",
        "\n",
        "                if epoch_acc>best_accuracy and phase=='val' :\n",
        "                    \n",
        "                    self.create_checkpoint(model,optimizer,best_path,epoch,loss_value)\n",
        "                    best_accuracy=epoch_acc\n",
        "        \n",
        "        \n",
        "        self.load_from_checkpoint(model,optimizer,best_path)\n",
        "\n",
        "        return model\n",
        "\n",
        "    def create_checkpoint(self,model,optimizer,path,epoch,loss):\n",
        "        \n",
        "        # basically copied from the tutorial, \n",
        "        # https://pytorch.org/tutorials/recipes/recipes/saving_and_loading_a_general_checkpoint.html\n",
        "\n",
        "        torch.save({\n",
        "              'epoch': epoch,\n",
        "              'model_state_dict': model.state_dict(),\n",
        "              'optimizer_state_dict': optimizer.state_dict(),\n",
        "              'loss': loss,\n",
        "              }, path)\n",
        "        \n",
        "    def load_from_checkpoint(self,model,optimizer,path):\n",
        "        \n",
        "        # basically copied from the tutorial, \n",
        "        # https://pytorch.org/tutorials/recipes/recipes/saving_and_loading_a_general_checkpoint.html\n",
        "        \n",
        "        checkpoint = torch.load(path)\n",
        "        model.load_state_dict(checkpoint['model_state_dict'])\n",
        "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "\n",
        "        print('reloading best model of epoch %d, loss %f'%(checkpoint['epoch'],checkpoint['loss']))\n",
        "\n",
        "    \n",
        "    def run(self,num_ep=10):\n",
        "        #Processing data\n",
        "        #Job = BaseLine()\n",
        "        #Job.folder_generator()\n",
        "        #train_dataloader, validation_dataloader = Job.data_loader('drive/My Drive/AML2020/train0')\n",
        "        #train_dataloader1, validation_dataloader1 = Job.data_loader('drive/My Drive/AML2020/train1')\n",
        "        #train_dataloader2, validation_dataloader2 = Job.data_loader('drive/My Drive/AML2020/train2')\n",
        "        #train_dataloader3, validation_dataloader3 = Job.data_loader('drive/My Drive/AML2020/train3')\n",
        "        #train_dataloader4, validation_dataloader4 = Job.data_loader('drive/My Drive/AML2020/train4')\n",
        "        #Job.show_images(train_dataloader)\n",
        "        \n",
        "        #Define model\n",
        "        #model, loss, optimizer, scheduler, device = Job.model()\n",
        "        #print(model, loss, optimizer, scheduler)\n",
        "        #Train model \n",
        "        #trained_model = Job.train_model(model, loss, optimizer, scheduler, train_dataloader, validation_dataloader, device, num_epochs=num_ep)\n",
        "        #trained_model1 = Job.train_model(model, loss, optimizer, scheduler, train_dataloader1, validation_dataloader1, device, num_epochs=num_ep)\n",
        "        #trained_model2 = Job.train_model(model, loss, optimizer, scheduler, train_dataloader2, validation_dataloader2, device, num_epochs=num_ep)\n",
        "        #trained_model3 = Job.train_model(model, loss, optimizer, scheduler, train_dataloader3, validation_dataloader3, device, num_epochs=num_ep)\n",
        "        #trained_model4 = Job.train_model(model, loss, optimizer, scheduler, train_dataloader4, validation_dataloader4, device, num_epochs=num_ep)\n",
        "        #return trained_model, trained_model1, trained_model2, trained_model3, trained_model4\n",
        "        #return trained_model\n",
        "\n",
        "\n",
        "\n",
        "        train_dataloader, validation_dataloader = self.data_loader()\n",
        "        \n",
        "        #Define model\n",
        "        \n",
        "        model, loss, optimizer, scheduler, device = self.model()\n",
        "\n",
        "        #Train model \n",
        "        \n",
        "        trained_model = self.train_model(model, loss, optimizer, scheduler, train_dataloader, validation_dataloader,\n",
        "                                         device, num_epochs=num_ep)\n",
        "        return trained_model"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bg57S9lzQmLw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8554975b-2c3e-4662-8e29-477847de9411"
      },
      "source": [
        "model = BaseLine().run()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1132 855\n",
            "71 54\n",
            "Epoch 0/9:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n",
            "100%|██████████| 71/71 [00:41<00:00,  1.72it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train Loss: 0.6235 Acc: 0.6617 Tiger Acc: 0.4921 Not Tiger Acc: 0.5079\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 54/54 [00:08<00:00,  6.02it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val Loss: 0.4971 Acc: 0.8275 Tiger Acc: 0.7488 Not Tiger Acc: 0.2512\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/9:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 71/71 [00:11<00:00,  6.04it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train Loss: 0.5163 Acc: 0.7717 Tiger Acc: 0.5073 Not Tiger Acc: 0.4927\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 54/54 [00:08<00:00,  6.08it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val Loss: 0.4431 Acc: 0.8275 Tiger Acc: 0.7303 Not Tiger Acc: 0.2697\n",
            "Epoch 2/9:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 71/71 [00:11<00:00,  6.15it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train Loss: 0.5221 Acc: 0.7303 Tiger Acc: 0.5062 Not Tiger Acc: 0.4938\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 54/54 [00:08<00:00,  6.13it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val Loss: 0.3903 Acc: 0.8480 Tiger Acc: 0.7594 Not Tiger Acc: 0.2406\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 3/9:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 71/71 [00:11<00:00,  6.21it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train Loss: 0.4525 Acc: 0.7946 Tiger Acc: 0.5021 Not Tiger Acc: 0.4979\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 54/54 [00:08<00:00,  6.08it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val Loss: 0.3553 Acc: 0.8562 Tiger Acc: 0.7798 Not Tiger Acc: 0.2202\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 4/9:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 71/71 [00:11<00:00,  6.11it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train Loss: 0.4305 Acc: 0.8148 Tiger Acc: 0.4927 Not Tiger Acc: 0.5073\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 54/54 [00:08<00:00,  6.17it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val Loss: 0.3504 Acc: 0.8581 Tiger Acc: 0.7763 Not Tiger Acc: 0.2237\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 5/9:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 71/71 [00:11<00:00,  6.00it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train Loss: 0.4127 Acc: 0.8292 Tiger Acc: 0.4883 Not Tiger Acc: 0.5117\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 54/54 [00:08<00:00,  6.02it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val Loss: 0.3648 Acc: 0.8515 Tiger Acc: 0.7574 Not Tiger Acc: 0.2426\n",
            "Epoch 6/9:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 71/71 [00:11<00:00,  6.13it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train Loss: 0.4252 Acc: 0.8060 Tiger Acc: 0.4979 Not Tiger Acc: 0.5021\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 54/54 [00:08<00:00,  6.01it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val Loss: 0.3649 Acc: 0.8484 Tiger Acc: 0.7497 Not Tiger Acc: 0.2503\n",
            "Epoch 7/9:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 71/71 [00:11<00:00,  6.07it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train Loss: 0.4103 Acc: 0.8187 Tiger Acc: 0.4950 Not Tiger Acc: 0.5050\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 54/54 [00:08<00:00,  6.06it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val Loss: 0.3598 Acc: 0.8504 Tiger Acc: 0.7586 Not Tiger Acc: 0.2414\n",
            "Epoch 8/9:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 71/71 [00:11<00:00,  6.09it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train Loss: 0.4163 Acc: 0.8069 Tiger Acc: 0.4903 Not Tiger Acc: 0.5097\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 54/54 [00:09<00:00,  5.97it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val Loss: 0.4070 Acc: 0.8275 Tiger Acc: 0.7103 Not Tiger Acc: 0.2897\n",
            "Epoch 9/9:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 71/71 [00:11<00:00,  6.07it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train Loss: 0.4050 Acc: 0.8260 Tiger Acc: 0.5044 Not Tiger Acc: 0.4956\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 54/54 [00:08<00:00,  6.03it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val Loss: 0.3426 Acc: 0.8608 Tiger Acc: 0.7728 Not Tiger Acc: 0.2272\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "reloading best model of epoch 9, loss 0.327450\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fw0XqoqKJ78P"
      },
      "source": [
        "def model_(n,basedir='drive/My Drive/AML2020/'):\n",
        "    \n",
        "    \n",
        "    \n",
        "    model=BaseLine(\n",
        "    train_path_=os.path.join(basedir,'train'+str(n)),\n",
        "    valid_path_=os.path.join(basedir,'validation'),\n",
        "    test_path_=os.path.join(basedir,'test'),\n",
        "    no_=n)\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YxBn4sbRKuc_",
        "outputId": "30c60884-f4a4-488f-9681-810af6d6ce10"
      },
      "source": [
        "models={}\n",
        "for i in range(5):\n",
        "    m=model_(i)\n",
        "    trained_m=m.run(num_ep=0)\n",
        "    models[i]=trained_m"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1136 855\n",
            "71 54\n",
            "reloading best model of epoch 1, loss 0.413348\n",
            "1132 855\n",
            "71 54\n",
            "reloading best model of epoch 0, loss 0.327840\n",
            "1132 855\n",
            "71 54\n",
            "reloading best model of epoch 1, loss 0.426961\n",
            "1132 855\n",
            "71 54\n",
            "reloading best model of epoch 3, loss 0.318388\n",
            "1132 855\n",
            "71 54\n",
            "reloading best model of epoch 9, loss 0.327450\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2z5ixf4H6oD"
      },
      "source": [
        "import pandas as pd\n",
        "import pickle\n",
        "\n",
        "def softmax(tensor):\n",
        "    \n",
        "    z=np.sum(np.exp(np.asarray(tensor)))\n",
        "    \n",
        "    return np.exp(np.asarray(tensor))/z\n",
        "\n",
        "\n",
        "def confidency(preds):\n",
        "    \n",
        "    confidencies=[]\n",
        "    \n",
        "    for pic in range(preds.shape[0]):\n",
        "        \n",
        "        confidencies.append(softmax(preds[pic,:])[1]) # guess that this is the tiger probability\n",
        "        \n",
        "    return confidencies"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47rh7_nuIJZm"
      },
      "source": [
        "#test_tiger_names_all=os.listdir('drive/My Drive/AML2020/validation/tiger')\n",
        "test_other_names=os.listdir('drive/My Drive/AML2020/validation/not_tiger')\n",
        "test_tiger_names=random.sample(os.listdir('drive/My Drive/AML2020/validation/tiger'),len(test_other_names))\n",
        "\n",
        "batch_size=10\n",
        "counter=0\n",
        "to_batch=[]\n",
        "results={}\n",
        "\n",
        "val_transforms = transforms.Compose([\n",
        "            transforms.Resize((224, 224)),\n",
        "            transforms.ToTensor(), \n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "        ])\n",
        "\n",
        "for id_,model in models.items():\n",
        "    results[id_]={}\n",
        "    model.eval()\n",
        "\n",
        "for pic in test_other_names:\n",
        "    to_batch.append((pic,val_transforms(Image.open('drive/My Drive/AML2020/validation/not_tiger/'+pic))))\n",
        "    counter+=1\n",
        "    \n",
        "    if counter==batch_size:\n",
        "        \n",
        "        batch=torch.cat([(item[1].reshape(-1,3,224,224)).cuda() for item in to_batch ])\n",
        "        \n",
        "        for id_,model in models.items():\n",
        "            \n",
        "            conf=confidency(model(batch).cpu().detach().numpy())\n",
        "            \n",
        "            for idx,item in enumerate(to_batch):\n",
        "            \n",
        "                results[id_][item[0]]=conf[idx]\n",
        "                \n",
        "        counter=0\n",
        "        to_batch=[]\n",
        "        \n",
        "for pic in test_tiger_names:\n",
        "    to_batch.append((pic,val_transforms(Image.open('drive/My Drive/AML2020/validation/tiger/'+pic).convert('RGB'))))\n",
        "    counter+=1\n",
        "    \n",
        "    if counter==batch_size:\n",
        "        \n",
        "        batch=torch.cat([(item[1].reshape(-1,3,224,224)).cuda() for item in to_batch ])\n",
        "        \n",
        "        for id_,model in models.items():\n",
        "            \n",
        "            conf=confidency(model(batch).cpu().detach().numpy())\n",
        "            \n",
        "            for idx,item in enumerate(to_batch):\n",
        "            \n",
        "                results[id_][item[0]]=conf[idx]\n",
        "                \n",
        "        counter=0\n",
        "        to_batch=[]\n",
        "    \n",
        "            \n",
        "if len(to_batch)>0: #some pics remained unevaluated\n",
        "    \n",
        "    batch=torch.cat([(item[1].reshape(-1,3,224,224)).cuda() for item in to_batch ])\n",
        "        \n",
        "    for id_,model in models.items():\n",
        "\n",
        "        conf=confidency(model(batch).cpu().detach().numpy())\n",
        "\n",
        "        for idx,item in enumerate(to_batch):\n",
        "\n",
        "            results[id_][item[0]]=conf[idx]\n",
        "\n",
        "    counter=0\n",
        "    to_batch=[]"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Wc_MiJ7z2OD"
      },
      "source": [
        "import copy"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JO0VDYAL0o8b"
      },
      "source": [
        "rr=copy.deepcopy(results)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xChE6Ebr0uap"
      },
      "source": [
        "for idx,model in models.items():\n",
        "    for key,value in rr[idx].items():\n",
        "        rr[idx][key]=list([value,])"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "id": "ZlIrjwXw03fM",
        "outputId": "751ab865-5871-4306-f7cc-dfc39fc06b98"
      },
      "source": [
        "pd.DataFrame.from_dict(rr[0])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>train_14.png</th>\n",
              "      <th>train_24.png</th>\n",
              "      <th>train_49.png</th>\n",
              "      <th>train_104.png</th>\n",
              "      <th>train_199.png</th>\n",
              "      <th>train_244.png</th>\n",
              "      <th>train_249.png</th>\n",
              "      <th>train_314.png</th>\n",
              "      <th>train_364.png</th>\n",
              "      <th>train_384.png</th>\n",
              "      <th>train_394.png</th>\n",
              "      <th>train_424.png</th>\n",
              "      <th>train_474.png</th>\n",
              "      <th>train_479.png</th>\n",
              "      <th>train_529.png</th>\n",
              "      <th>train_534.png</th>\n",
              "      <th>train_539.png</th>\n",
              "      <th>train_659.png</th>\n",
              "      <th>train_719.png</th>\n",
              "      <th>train_724.png</th>\n",
              "      <th>train_789.png</th>\n",
              "      <th>train_834.png</th>\n",
              "      <th>train_869.png</th>\n",
              "      <th>train_1004.png</th>\n",
              "      <th>train_1029.png</th>\n",
              "      <th>train_1034.png</th>\n",
              "      <th>train_1079.png</th>\n",
              "      <th>train_1084.png</th>\n",
              "      <th>train_1109.png</th>\n",
              "      <th>train_1124.png</th>\n",
              "      <th>train_1134.png</th>\n",
              "      <th>train_1139.png</th>\n",
              "      <th>train_1149.png</th>\n",
              "      <th>train_1179.png</th>\n",
              "      <th>train_1189.png</th>\n",
              "      <th>train_1229.png</th>\n",
              "      <th>train_1294.png</th>\n",
              "      <th>train_1299.png</th>\n",
              "      <th>train_1309.png</th>\n",
              "      <th>train_1339.png</th>\n",
              "      <th>...</th>\n",
              "      <th>train_3529.png</th>\n",
              "      <th>train_3254.png</th>\n",
              "      <th>train_3069.png</th>\n",
              "      <th>train_2279.png</th>\n",
              "      <th>train_1969.png</th>\n",
              "      <th>train_389.png</th>\n",
              "      <th>train_909.png</th>\n",
              "      <th>train_319.png</th>\n",
              "      <th>train_1319.png</th>\n",
              "      <th>train_3789.png</th>\n",
              "      <th>train_1964.png</th>\n",
              "      <th>train_1749.png</th>\n",
              "      <th>train_809.png</th>\n",
              "      <th>train_1039.png</th>\n",
              "      <th>train_1269.png</th>\n",
              "      <th>train_334.png</th>\n",
              "      <th>train_3039.png</th>\n",
              "      <th>train_2759.png</th>\n",
              "      <th>train_64.png</th>\n",
              "      <th>train_1854.png</th>\n",
              "      <th>train_2104.png</th>\n",
              "      <th>train_2374.png</th>\n",
              "      <th>train_354.png</th>\n",
              "      <th>train_3869.png</th>\n",
              "      <th>train_1834.png</th>\n",
              "      <th>train_2769.png</th>\n",
              "      <th>train_664.png</th>\n",
              "      <th>train_969.png</th>\n",
              "      <th>train_2254.png</th>\n",
              "      <th>train_1569.png</th>\n",
              "      <th>train_3164.png</th>\n",
              "      <th>train_3769.png</th>\n",
              "      <th>train_2639.png</th>\n",
              "      <th>train_669.png</th>\n",
              "      <th>train_3284.png</th>\n",
              "      <th>train_114.png</th>\n",
              "      <th>train_3484.png</th>\n",
              "      <th>train_1599.png</th>\n",
              "      <th>train_559.png</th>\n",
              "      <th>train_3604.png</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.321682</td>\n",
              "      <td>0.272577</td>\n",
              "      <td>0.47895</td>\n",
              "      <td>0.73412</td>\n",
              "      <td>0.454799</td>\n",
              "      <td>0.300852</td>\n",
              "      <td>0.44797</td>\n",
              "      <td>0.632022</td>\n",
              "      <td>0.214687</td>\n",
              "      <td>0.41628</td>\n",
              "      <td>0.318279</td>\n",
              "      <td>0.658559</td>\n",
              "      <td>0.565169</td>\n",
              "      <td>0.597355</td>\n",
              "      <td>0.66286</td>\n",
              "      <td>0.390485</td>\n",
              "      <td>0.533042</td>\n",
              "      <td>0.455886</td>\n",
              "      <td>0.512667</td>\n",
              "      <td>0.42909</td>\n",
              "      <td>0.490204</td>\n",
              "      <td>0.458703</td>\n",
              "      <td>0.41283</td>\n",
              "      <td>0.590615</td>\n",
              "      <td>0.275955</td>\n",
              "      <td>0.497062</td>\n",
              "      <td>0.401471</td>\n",
              "      <td>0.554731</td>\n",
              "      <td>0.275605</td>\n",
              "      <td>0.329288</td>\n",
              "      <td>0.289217</td>\n",
              "      <td>0.345265</td>\n",
              "      <td>0.358797</td>\n",
              "      <td>0.190883</td>\n",
              "      <td>0.269066</td>\n",
              "      <td>0.705226</td>\n",
              "      <td>0.800927</td>\n",
              "      <td>0.781056</td>\n",
              "      <td>0.388212</td>\n",
              "      <td>0.751998</td>\n",
              "      <td>...</td>\n",
              "      <td>0.810085</td>\n",
              "      <td>0.530151</td>\n",
              "      <td>0.749466</td>\n",
              "      <td>0.809851</td>\n",
              "      <td>0.637587</td>\n",
              "      <td>0.490916</td>\n",
              "      <td>0.882961</td>\n",
              "      <td>0.734355</td>\n",
              "      <td>0.686453</td>\n",
              "      <td>0.468105</td>\n",
              "      <td>0.742985</td>\n",
              "      <td>0.840924</td>\n",
              "      <td>0.88109</td>\n",
              "      <td>0.908864</td>\n",
              "      <td>0.734443</td>\n",
              "      <td>0.809612</td>\n",
              "      <td>0.902583</td>\n",
              "      <td>0.721046</td>\n",
              "      <td>0.696815</td>\n",
              "      <td>0.830402</td>\n",
              "      <td>0.832728</td>\n",
              "      <td>0.835908</td>\n",
              "      <td>0.818141</td>\n",
              "      <td>0.62454</td>\n",
              "      <td>0.68871</td>\n",
              "      <td>0.64001</td>\n",
              "      <td>0.881034</td>\n",
              "      <td>0.708</td>\n",
              "      <td>0.822211</td>\n",
              "      <td>0.379919</td>\n",
              "      <td>0.630172</td>\n",
              "      <td>0.729037</td>\n",
              "      <td>0.895639</td>\n",
              "      <td>0.291278</td>\n",
              "      <td>0.62864</td>\n",
              "      <td>0.708667</td>\n",
              "      <td>0.693401</td>\n",
              "      <td>0.87011</td>\n",
              "      <td>0.853622</td>\n",
              "      <td>0.85504</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1 rows × 272 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   train_14.png  train_24.png  ...  train_559.png  train_3604.png\n",
              "0      0.321682      0.272577  ...       0.853622         0.85504\n",
              "\n",
              "[1 rows x 272 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0MsYN3it1DhB"
      },
      "source": [
        "tabular_res=pd.concat([pd.DataFrame.from_dict(rr[i]) for i in range(5)])"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "id": "X7-6GJhL1E59",
        "outputId": "d469e802-8ed6-4b52-cf60-59c9005f94e2"
      },
      "source": [
        "tabular_res"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>train_14.png</th>\n",
              "      <th>train_24.png</th>\n",
              "      <th>train_49.png</th>\n",
              "      <th>train_104.png</th>\n",
              "      <th>train_199.png</th>\n",
              "      <th>train_244.png</th>\n",
              "      <th>train_249.png</th>\n",
              "      <th>train_314.png</th>\n",
              "      <th>train_364.png</th>\n",
              "      <th>train_384.png</th>\n",
              "      <th>train_394.png</th>\n",
              "      <th>train_424.png</th>\n",
              "      <th>train_474.png</th>\n",
              "      <th>train_479.png</th>\n",
              "      <th>train_529.png</th>\n",
              "      <th>train_534.png</th>\n",
              "      <th>train_539.png</th>\n",
              "      <th>train_659.png</th>\n",
              "      <th>train_719.png</th>\n",
              "      <th>train_724.png</th>\n",
              "      <th>train_789.png</th>\n",
              "      <th>train_834.png</th>\n",
              "      <th>train_869.png</th>\n",
              "      <th>train_1004.png</th>\n",
              "      <th>train_1029.png</th>\n",
              "      <th>train_1034.png</th>\n",
              "      <th>train_1079.png</th>\n",
              "      <th>train_1084.png</th>\n",
              "      <th>train_1109.png</th>\n",
              "      <th>train_1124.png</th>\n",
              "      <th>train_1134.png</th>\n",
              "      <th>train_1139.png</th>\n",
              "      <th>train_1149.png</th>\n",
              "      <th>train_1179.png</th>\n",
              "      <th>train_1189.png</th>\n",
              "      <th>train_1229.png</th>\n",
              "      <th>train_1294.png</th>\n",
              "      <th>train_1299.png</th>\n",
              "      <th>train_1309.png</th>\n",
              "      <th>train_1339.png</th>\n",
              "      <th>...</th>\n",
              "      <th>train_3529.png</th>\n",
              "      <th>train_3254.png</th>\n",
              "      <th>train_3069.png</th>\n",
              "      <th>train_2279.png</th>\n",
              "      <th>train_1969.png</th>\n",
              "      <th>train_389.png</th>\n",
              "      <th>train_909.png</th>\n",
              "      <th>train_319.png</th>\n",
              "      <th>train_1319.png</th>\n",
              "      <th>train_3789.png</th>\n",
              "      <th>train_1964.png</th>\n",
              "      <th>train_1749.png</th>\n",
              "      <th>train_809.png</th>\n",
              "      <th>train_1039.png</th>\n",
              "      <th>train_1269.png</th>\n",
              "      <th>train_334.png</th>\n",
              "      <th>train_3039.png</th>\n",
              "      <th>train_2759.png</th>\n",
              "      <th>train_64.png</th>\n",
              "      <th>train_1854.png</th>\n",
              "      <th>train_2104.png</th>\n",
              "      <th>train_2374.png</th>\n",
              "      <th>train_354.png</th>\n",
              "      <th>train_3869.png</th>\n",
              "      <th>train_1834.png</th>\n",
              "      <th>train_2769.png</th>\n",
              "      <th>train_664.png</th>\n",
              "      <th>train_969.png</th>\n",
              "      <th>train_2254.png</th>\n",
              "      <th>train_1569.png</th>\n",
              "      <th>train_3164.png</th>\n",
              "      <th>train_3769.png</th>\n",
              "      <th>train_2639.png</th>\n",
              "      <th>train_669.png</th>\n",
              "      <th>train_3284.png</th>\n",
              "      <th>train_114.png</th>\n",
              "      <th>train_3484.png</th>\n",
              "      <th>train_1599.png</th>\n",
              "      <th>train_559.png</th>\n",
              "      <th>train_3604.png</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.321682</td>\n",
              "      <td>0.272577</td>\n",
              "      <td>0.478950</td>\n",
              "      <td>0.734120</td>\n",
              "      <td>0.454799</td>\n",
              "      <td>0.300852</td>\n",
              "      <td>0.447970</td>\n",
              "      <td>0.632022</td>\n",
              "      <td>0.214687</td>\n",
              "      <td>0.416280</td>\n",
              "      <td>0.318279</td>\n",
              "      <td>0.658559</td>\n",
              "      <td>0.565169</td>\n",
              "      <td>0.597355</td>\n",
              "      <td>0.662860</td>\n",
              "      <td>0.390485</td>\n",
              "      <td>0.533042</td>\n",
              "      <td>0.455886</td>\n",
              "      <td>0.512667</td>\n",
              "      <td>0.429090</td>\n",
              "      <td>0.490204</td>\n",
              "      <td>0.458703</td>\n",
              "      <td>0.412830</td>\n",
              "      <td>0.590615</td>\n",
              "      <td>0.275955</td>\n",
              "      <td>0.497062</td>\n",
              "      <td>0.401471</td>\n",
              "      <td>0.554731</td>\n",
              "      <td>0.275605</td>\n",
              "      <td>0.329288</td>\n",
              "      <td>0.289217</td>\n",
              "      <td>0.345265</td>\n",
              "      <td>0.358797</td>\n",
              "      <td>0.190883</td>\n",
              "      <td>0.269066</td>\n",
              "      <td>0.705226</td>\n",
              "      <td>0.800927</td>\n",
              "      <td>0.781056</td>\n",
              "      <td>0.388212</td>\n",
              "      <td>0.751998</td>\n",
              "      <td>...</td>\n",
              "      <td>0.810085</td>\n",
              "      <td>0.530151</td>\n",
              "      <td>0.749466</td>\n",
              "      <td>0.809851</td>\n",
              "      <td>0.637587</td>\n",
              "      <td>0.490916</td>\n",
              "      <td>0.882961</td>\n",
              "      <td>0.734355</td>\n",
              "      <td>0.686453</td>\n",
              "      <td>0.468105</td>\n",
              "      <td>0.742985</td>\n",
              "      <td>0.840924</td>\n",
              "      <td>0.881090</td>\n",
              "      <td>0.908864</td>\n",
              "      <td>0.734443</td>\n",
              "      <td>0.809612</td>\n",
              "      <td>0.902583</td>\n",
              "      <td>0.721046</td>\n",
              "      <td>0.696815</td>\n",
              "      <td>0.830402</td>\n",
              "      <td>0.832728</td>\n",
              "      <td>0.835908</td>\n",
              "      <td>0.818141</td>\n",
              "      <td>0.624540</td>\n",
              "      <td>0.688710</td>\n",
              "      <td>0.640010</td>\n",
              "      <td>0.881034</td>\n",
              "      <td>0.708000</td>\n",
              "      <td>0.822211</td>\n",
              "      <td>0.379919</td>\n",
              "      <td>0.630172</td>\n",
              "      <td>0.729037</td>\n",
              "      <td>0.895639</td>\n",
              "      <td>0.291278</td>\n",
              "      <td>0.628640</td>\n",
              "      <td>0.708667</td>\n",
              "      <td>0.693401</td>\n",
              "      <td>0.870110</td>\n",
              "      <td>0.853622</td>\n",
              "      <td>0.855040</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.365714</td>\n",
              "      <td>0.282509</td>\n",
              "      <td>0.357999</td>\n",
              "      <td>0.524438</td>\n",
              "      <td>0.439248</td>\n",
              "      <td>0.377805</td>\n",
              "      <td>0.369665</td>\n",
              "      <td>0.521319</td>\n",
              "      <td>0.289453</td>\n",
              "      <td>0.499914</td>\n",
              "      <td>0.497540</td>\n",
              "      <td>0.635635</td>\n",
              "      <td>0.599282</td>\n",
              "      <td>0.628820</td>\n",
              "      <td>0.608196</td>\n",
              "      <td>0.437503</td>\n",
              "      <td>0.485574</td>\n",
              "      <td>0.390435</td>\n",
              "      <td>0.509619</td>\n",
              "      <td>0.380368</td>\n",
              "      <td>0.318379</td>\n",
              "      <td>0.441341</td>\n",
              "      <td>0.445841</td>\n",
              "      <td>0.518129</td>\n",
              "      <td>0.465693</td>\n",
              "      <td>0.605811</td>\n",
              "      <td>0.542409</td>\n",
              "      <td>0.548721</td>\n",
              "      <td>0.295875</td>\n",
              "      <td>0.346129</td>\n",
              "      <td>0.486694</td>\n",
              "      <td>0.448287</td>\n",
              "      <td>0.555921</td>\n",
              "      <td>0.369936</td>\n",
              "      <td>0.271833</td>\n",
              "      <td>0.583823</td>\n",
              "      <td>0.675620</td>\n",
              "      <td>0.779502</td>\n",
              "      <td>0.515950</td>\n",
              "      <td>0.700301</td>\n",
              "      <td>...</td>\n",
              "      <td>0.614150</td>\n",
              "      <td>0.570982</td>\n",
              "      <td>0.737185</td>\n",
              "      <td>0.643615</td>\n",
              "      <td>0.633888</td>\n",
              "      <td>0.696764</td>\n",
              "      <td>0.827484</td>\n",
              "      <td>0.764488</td>\n",
              "      <td>0.678155</td>\n",
              "      <td>0.344995</td>\n",
              "      <td>0.737712</td>\n",
              "      <td>0.795875</td>\n",
              "      <td>0.862900</td>\n",
              "      <td>0.756962</td>\n",
              "      <td>0.637736</td>\n",
              "      <td>0.685823</td>\n",
              "      <td>0.823395</td>\n",
              "      <td>0.713039</td>\n",
              "      <td>0.612043</td>\n",
              "      <td>0.752883</td>\n",
              "      <td>0.818817</td>\n",
              "      <td>0.764948</td>\n",
              "      <td>0.768414</td>\n",
              "      <td>0.519941</td>\n",
              "      <td>0.780763</td>\n",
              "      <td>0.629065</td>\n",
              "      <td>0.828052</td>\n",
              "      <td>0.692472</td>\n",
              "      <td>0.802870</td>\n",
              "      <td>0.453075</td>\n",
              "      <td>0.562403</td>\n",
              "      <td>0.595350</td>\n",
              "      <td>0.852461</td>\n",
              "      <td>0.482910</td>\n",
              "      <td>0.548160</td>\n",
              "      <td>0.593213</td>\n",
              "      <td>0.649474</td>\n",
              "      <td>0.781546</td>\n",
              "      <td>0.749847</td>\n",
              "      <td>0.791324</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.433261</td>\n",
              "      <td>0.366069</td>\n",
              "      <td>0.452396</td>\n",
              "      <td>0.752962</td>\n",
              "      <td>0.447858</td>\n",
              "      <td>0.393720</td>\n",
              "      <td>0.304830</td>\n",
              "      <td>0.628200</td>\n",
              "      <td>0.192042</td>\n",
              "      <td>0.522005</td>\n",
              "      <td>0.323262</td>\n",
              "      <td>0.641914</td>\n",
              "      <td>0.714856</td>\n",
              "      <td>0.618335</td>\n",
              "      <td>0.707025</td>\n",
              "      <td>0.331185</td>\n",
              "      <td>0.678933</td>\n",
              "      <td>0.362019</td>\n",
              "      <td>0.380409</td>\n",
              "      <td>0.528334</td>\n",
              "      <td>0.473488</td>\n",
              "      <td>0.444433</td>\n",
              "      <td>0.392673</td>\n",
              "      <td>0.572747</td>\n",
              "      <td>0.371327</td>\n",
              "      <td>0.451850</td>\n",
              "      <td>0.542803</td>\n",
              "      <td>0.488676</td>\n",
              "      <td>0.379896</td>\n",
              "      <td>0.433824</td>\n",
              "      <td>0.453740</td>\n",
              "      <td>0.462424</td>\n",
              "      <td>0.327485</td>\n",
              "      <td>0.278034</td>\n",
              "      <td>0.362372</td>\n",
              "      <td>0.646871</td>\n",
              "      <td>0.643107</td>\n",
              "      <td>0.797951</td>\n",
              "      <td>0.318580</td>\n",
              "      <td>0.819879</td>\n",
              "      <td>...</td>\n",
              "      <td>0.847779</td>\n",
              "      <td>0.639064</td>\n",
              "      <td>0.697180</td>\n",
              "      <td>0.892175</td>\n",
              "      <td>0.808827</td>\n",
              "      <td>0.676127</td>\n",
              "      <td>0.894164</td>\n",
              "      <td>0.829015</td>\n",
              "      <td>0.762056</td>\n",
              "      <td>0.582657</td>\n",
              "      <td>0.875444</td>\n",
              "      <td>0.923305</td>\n",
              "      <td>0.908349</td>\n",
              "      <td>0.903485</td>\n",
              "      <td>0.767621</td>\n",
              "      <td>0.865004</td>\n",
              "      <td>0.944454</td>\n",
              "      <td>0.848170</td>\n",
              "      <td>0.741231</td>\n",
              "      <td>0.856424</td>\n",
              "      <td>0.867067</td>\n",
              "      <td>0.892852</td>\n",
              "      <td>0.830194</td>\n",
              "      <td>0.675018</td>\n",
              "      <td>0.773402</td>\n",
              "      <td>0.645332</td>\n",
              "      <td>0.904152</td>\n",
              "      <td>0.692863</td>\n",
              "      <td>0.862108</td>\n",
              "      <td>0.491251</td>\n",
              "      <td>0.754335</td>\n",
              "      <td>0.808993</td>\n",
              "      <td>0.912367</td>\n",
              "      <td>0.360213</td>\n",
              "      <td>0.686543</td>\n",
              "      <td>0.781120</td>\n",
              "      <td>0.730210</td>\n",
              "      <td>0.861207</td>\n",
              "      <td>0.828545</td>\n",
              "      <td>0.873877</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.190830</td>\n",
              "      <td>0.159153</td>\n",
              "      <td>0.336512</td>\n",
              "      <td>0.660598</td>\n",
              "      <td>0.282657</td>\n",
              "      <td>0.166318</td>\n",
              "      <td>0.195617</td>\n",
              "      <td>0.465790</td>\n",
              "      <td>0.038029</td>\n",
              "      <td>0.206073</td>\n",
              "      <td>0.305363</td>\n",
              "      <td>0.547090</td>\n",
              "      <td>0.534114</td>\n",
              "      <td>0.436248</td>\n",
              "      <td>0.527856</td>\n",
              "      <td>0.129040</td>\n",
              "      <td>0.333979</td>\n",
              "      <td>0.176519</td>\n",
              "      <td>0.205510</td>\n",
              "      <td>0.321383</td>\n",
              "      <td>0.178332</td>\n",
              "      <td>0.256641</td>\n",
              "      <td>0.225650</td>\n",
              "      <td>0.458416</td>\n",
              "      <td>0.134131</td>\n",
              "      <td>0.394176</td>\n",
              "      <td>0.279430</td>\n",
              "      <td>0.434586</td>\n",
              "      <td>0.116649</td>\n",
              "      <td>0.210843</td>\n",
              "      <td>0.250801</td>\n",
              "      <td>0.250024</td>\n",
              "      <td>0.245168</td>\n",
              "      <td>0.151623</td>\n",
              "      <td>0.119220</td>\n",
              "      <td>0.582648</td>\n",
              "      <td>0.687115</td>\n",
              "      <td>0.614779</td>\n",
              "      <td>0.156716</td>\n",
              "      <td>0.759025</td>\n",
              "      <td>...</td>\n",
              "      <td>0.777090</td>\n",
              "      <td>0.501768</td>\n",
              "      <td>0.819801</td>\n",
              "      <td>0.877401</td>\n",
              "      <td>0.693376</td>\n",
              "      <td>0.529280</td>\n",
              "      <td>0.906052</td>\n",
              "      <td>0.825027</td>\n",
              "      <td>0.725910</td>\n",
              "      <td>0.402522</td>\n",
              "      <td>0.909433</td>\n",
              "      <td>0.877946</td>\n",
              "      <td>0.942980</td>\n",
              "      <td>0.918231</td>\n",
              "      <td>0.790907</td>\n",
              "      <td>0.826729</td>\n",
              "      <td>0.951260</td>\n",
              "      <td>0.701018</td>\n",
              "      <td>0.664659</td>\n",
              "      <td>0.843088</td>\n",
              "      <td>0.882182</td>\n",
              "      <td>0.879584</td>\n",
              "      <td>0.782930</td>\n",
              "      <td>0.768826</td>\n",
              "      <td>0.788208</td>\n",
              "      <td>0.634335</td>\n",
              "      <td>0.913735</td>\n",
              "      <td>0.720962</td>\n",
              "      <td>0.879944</td>\n",
              "      <td>0.374249</td>\n",
              "      <td>0.769729</td>\n",
              "      <td>0.800342</td>\n",
              "      <td>0.954888</td>\n",
              "      <td>0.282444</td>\n",
              "      <td>0.605888</td>\n",
              "      <td>0.543608</td>\n",
              "      <td>0.808360</td>\n",
              "      <td>0.809222</td>\n",
              "      <td>0.805761</td>\n",
              "      <td>0.892051</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.103369</td>\n",
              "      <td>0.108622</td>\n",
              "      <td>0.229397</td>\n",
              "      <td>0.761692</td>\n",
              "      <td>0.267768</td>\n",
              "      <td>0.112954</td>\n",
              "      <td>0.066118</td>\n",
              "      <td>0.530732</td>\n",
              "      <td>0.020139</td>\n",
              "      <td>0.180160</td>\n",
              "      <td>0.225933</td>\n",
              "      <td>0.549939</td>\n",
              "      <td>0.515057</td>\n",
              "      <td>0.415873</td>\n",
              "      <td>0.747024</td>\n",
              "      <td>0.071350</td>\n",
              "      <td>0.329684</td>\n",
              "      <td>0.126923</td>\n",
              "      <td>0.110404</td>\n",
              "      <td>0.270331</td>\n",
              "      <td>0.082808</td>\n",
              "      <td>0.328034</td>\n",
              "      <td>0.137831</td>\n",
              "      <td>0.409719</td>\n",
              "      <td>0.047831</td>\n",
              "      <td>0.194032</td>\n",
              "      <td>0.289041</td>\n",
              "      <td>0.377262</td>\n",
              "      <td>0.104794</td>\n",
              "      <td>0.160284</td>\n",
              "      <td>0.186911</td>\n",
              "      <td>0.149932</td>\n",
              "      <td>0.170929</td>\n",
              "      <td>0.075931</td>\n",
              "      <td>0.056795</td>\n",
              "      <td>0.613997</td>\n",
              "      <td>0.572451</td>\n",
              "      <td>0.673119</td>\n",
              "      <td>0.077450</td>\n",
              "      <td>0.708762</td>\n",
              "      <td>...</td>\n",
              "      <td>0.804399</td>\n",
              "      <td>0.553865</td>\n",
              "      <td>0.678496</td>\n",
              "      <td>0.854503</td>\n",
              "      <td>0.670349</td>\n",
              "      <td>0.693079</td>\n",
              "      <td>0.944432</td>\n",
              "      <td>0.823936</td>\n",
              "      <td>0.793637</td>\n",
              "      <td>0.373617</td>\n",
              "      <td>0.899812</td>\n",
              "      <td>0.923006</td>\n",
              "      <td>0.958890</td>\n",
              "      <td>0.955224</td>\n",
              "      <td>0.788511</td>\n",
              "      <td>0.881334</td>\n",
              "      <td>0.974100</td>\n",
              "      <td>0.743565</td>\n",
              "      <td>0.632833</td>\n",
              "      <td>0.900871</td>\n",
              "      <td>0.913321</td>\n",
              "      <td>0.900574</td>\n",
              "      <td>0.785164</td>\n",
              "      <td>0.588321</td>\n",
              "      <td>0.708620</td>\n",
              "      <td>0.540462</td>\n",
              "      <td>0.959298</td>\n",
              "      <td>0.760132</td>\n",
              "      <td>0.846591</td>\n",
              "      <td>0.318457</td>\n",
              "      <td>0.673704</td>\n",
              "      <td>0.657037</td>\n",
              "      <td>0.975074</td>\n",
              "      <td>0.375615</td>\n",
              "      <td>0.540335</td>\n",
              "      <td>0.690474</td>\n",
              "      <td>0.807517</td>\n",
              "      <td>0.875580</td>\n",
              "      <td>0.763403</td>\n",
              "      <td>0.971440</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 272 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   train_14.png  train_24.png  ...  train_559.png  train_3604.png\n",
              "0      0.321682      0.272577  ...       0.853622        0.855040\n",
              "0      0.365714      0.282509  ...       0.749847        0.791324\n",
              "0      0.433261      0.366069  ...       0.828545        0.873877\n",
              "0      0.190830      0.159153  ...       0.805761        0.892051\n",
              "0      0.103369      0.108622  ...       0.763403        0.971440\n",
              "\n",
              "[5 rows x 272 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "RaaRIZns1Qec",
        "outputId": "57a52ca9-3940-4d95-ba7b-63b647852aaa"
      },
      "source": [
        "tabular_res.index=[0,1,2,3,4]\n",
        "data=tabular_res.transpose()\n",
        "data.head()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>train_14.png</th>\n",
              "      <td>0.321682</td>\n",
              "      <td>0.365714</td>\n",
              "      <td>0.433261</td>\n",
              "      <td>0.190830</td>\n",
              "      <td>0.103369</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>train_24.png</th>\n",
              "      <td>0.272577</td>\n",
              "      <td>0.282509</td>\n",
              "      <td>0.366069</td>\n",
              "      <td>0.159153</td>\n",
              "      <td>0.108622</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>train_49.png</th>\n",
              "      <td>0.478950</td>\n",
              "      <td>0.357999</td>\n",
              "      <td>0.452396</td>\n",
              "      <td>0.336512</td>\n",
              "      <td>0.229397</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>train_104.png</th>\n",
              "      <td>0.734120</td>\n",
              "      <td>0.524438</td>\n",
              "      <td>0.752962</td>\n",
              "      <td>0.660598</td>\n",
              "      <td>0.761692</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>train_199.png</th>\n",
              "      <td>0.454799</td>\n",
              "      <td>0.439248</td>\n",
              "      <td>0.447858</td>\n",
              "      <td>0.282657</td>\n",
              "      <td>0.267768</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                      0         1         2         3         4\n",
              "train_14.png   0.321682  0.365714  0.433261  0.190830  0.103369\n",
              "train_24.png   0.272577  0.282509  0.366069  0.159153  0.108622\n",
              "train_49.png   0.478950  0.357999  0.452396  0.336512  0.229397\n",
              "train_104.png  0.734120  0.524438  0.752962  0.660598  0.761692\n",
              "train_199.png  0.454799  0.439248  0.447858  0.282657  0.267768"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lIdjblZnyjk8"
      },
      "source": [
        "labels = pd.read_csv('drive/My Drive/AML2020/train.csv')\n",
        "indeces = []\n",
        "for pic in list(data.index):\n",
        "    index = list(labels['file']).index('images/'+pic)\n",
        "    indeces.append(index)\n",
        "\n",
        "labels_data = labels.iloc[indeces]\n",
        "data['labels'] = list(labels_data['is_tiger'])"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "3y6rpaK93JaY",
        "outputId": "1bffd095-230a-4c82-ef49-78117f9d7457"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>train_14.png</th>\n",
              "      <td>0.321682</td>\n",
              "      <td>0.365714</td>\n",
              "      <td>0.433261</td>\n",
              "      <td>0.190830</td>\n",
              "      <td>0.103369</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>train_24.png</th>\n",
              "      <td>0.272577</td>\n",
              "      <td>0.282509</td>\n",
              "      <td>0.366069</td>\n",
              "      <td>0.159153</td>\n",
              "      <td>0.108622</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>train_49.png</th>\n",
              "      <td>0.478950</td>\n",
              "      <td>0.357999</td>\n",
              "      <td>0.452396</td>\n",
              "      <td>0.336512</td>\n",
              "      <td>0.229397</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>train_104.png</th>\n",
              "      <td>0.734120</td>\n",
              "      <td>0.524438</td>\n",
              "      <td>0.752962</td>\n",
              "      <td>0.660598</td>\n",
              "      <td>0.761692</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>train_199.png</th>\n",
              "      <td>0.454799</td>\n",
              "      <td>0.439248</td>\n",
              "      <td>0.447858</td>\n",
              "      <td>0.282657</td>\n",
              "      <td>0.267768</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                      0         1         2         3         4  labels\n",
              "train_14.png   0.321682  0.365714  0.433261  0.190830  0.103369       0\n",
              "train_24.png   0.272577  0.282509  0.366069  0.159153  0.108622       0\n",
              "train_49.png   0.478950  0.357999  0.452396  0.336512  0.229397       0\n",
              "train_104.png  0.734120  0.524438  0.752962  0.660598  0.761692       0\n",
              "train_199.png  0.454799  0.439248  0.447858  0.282657  0.267768       0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pe29CYHD4iUA"
      },
      "source": [
        "for i in range(5):\r\n",
        "  data['threshold'+str(i)] = round(data[i])\r\n"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "3HTT4icR5FH3",
        "outputId": "66a1b26d-b456-4214-d222-d854f7200989"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>labels</th>\n",
              "      <th>threshold0</th>\n",
              "      <th>threshold1</th>\n",
              "      <th>threshold2</th>\n",
              "      <th>threshold3</th>\n",
              "      <th>threshold4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>train_14.png</th>\n",
              "      <td>0.321682</td>\n",
              "      <td>0.365714</td>\n",
              "      <td>0.433261</td>\n",
              "      <td>0.190830</td>\n",
              "      <td>0.103369</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>train_24.png</th>\n",
              "      <td>0.272577</td>\n",
              "      <td>0.282509</td>\n",
              "      <td>0.366069</td>\n",
              "      <td>0.159153</td>\n",
              "      <td>0.108622</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>train_49.png</th>\n",
              "      <td>0.478950</td>\n",
              "      <td>0.357999</td>\n",
              "      <td>0.452396</td>\n",
              "      <td>0.336512</td>\n",
              "      <td>0.229397</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>train_104.png</th>\n",
              "      <td>0.734120</td>\n",
              "      <td>0.524438</td>\n",
              "      <td>0.752962</td>\n",
              "      <td>0.660598</td>\n",
              "      <td>0.761692</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>train_199.png</th>\n",
              "      <td>0.454799</td>\n",
              "      <td>0.439248</td>\n",
              "      <td>0.447858</td>\n",
              "      <td>0.282657</td>\n",
              "      <td>0.267768</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                      0         1         2  ...  threshold2  threshold3  threshold4\n",
              "train_14.png   0.321682  0.365714  0.433261  ...         0.0         0.0         0.0\n",
              "train_24.png   0.272577  0.282509  0.366069  ...         0.0         0.0         0.0\n",
              "train_49.png   0.478950  0.357999  0.452396  ...         0.0         0.0         0.0\n",
              "train_104.png  0.734120  0.524438  0.752962  ...         1.0         1.0         1.0\n",
              "train_199.png  0.454799  0.439248  0.447858  ...         0.0         0.0         0.0\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BHEUp1gp303-"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import tree\n",
        "from sklearn import svm\n",
        "X, y = data[[0,1,2,3,4]], data['labels'] \n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
        "clf = LogisticRegression(random_state=0).fit(X_train,y_train)\n",
        "clf2 = svm.SVC().fit(X_train,y_train)\n",
        "clf3 = tree.DecisionTreeClassifier().fit(X_train,y_train)"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IaqocLxfrn3p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db9e7988-3e90-4818-d39e-55356a1dbed8"
      },
      "source": [
        "a0_train = np.reshape(X_train[0].to_numpy(),(-1,1))\n",
        "a0_test = np.reshape(X_test[0].to_numpy(),(-1,1))\n",
        "clf_0 = tree.DecisionTreeClassifier().fit(a0_train,y_train)\n",
        "X_test['dt0'] = clf_0.predict(a0_test)\n",
        "a1_train = np.reshape(X_train[1].to_numpy(),(-1,1))\n",
        "a1_test = np.reshape(X_test[1].to_numpy(),(-1,1))\n",
        "clf_1 = tree.DecisionTreeClassifier().fit(a1_train,y_train)\n",
        "X_test['dt1'] = clf_1.predict(a1_test)\n",
        "a2_train = np.reshape(X_train[2].to_numpy(),(-1,1))\n",
        "a2_test = np.reshape(X_test[2].to_numpy(),(-1,1))\n",
        "clf_2 = tree.DecisionTreeClassifier().fit(a2_train,y_train)\n",
        "X_test['dt2'] = clf_2.predict(a2_test)\n",
        "a3_train = np.reshape(X_train[3].to_numpy(),(-1,1))\n",
        "a3_test = np.reshape(X_test[3].to_numpy(),(-1,1))\n",
        "clf_3 = tree.DecisionTreeClassifier().fit(a3_train,y_train)\n",
        "X_test['dt3'] = clf_3.predict(a3_test)\n",
        "a4_train = np.reshape(X_train[4].to_numpy(),(-1,1))\n",
        "a4_test = np.reshape(X_test[4].to_numpy(),(-1,1))\n",
        "clf_4 = tree.DecisionTreeClassifier().fit(a4_train,y_train)\n",
        "X_test['dt4'] = clf_4.predict(a4_test)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if sys.path[0] == '':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQxgMn-Gy5Jw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2c10c90-49c5-42d0-81a4-03810d15a6dd"
      },
      "source": [
        "X_test['MV'] = round((X_test['dt0']+X_test['dt1']+X_test['dt2']+X_test['dt3']+X_test['dt4'])/5)\n",
        "\n",
        " "
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iLXhlwWS56ch",
        "outputId": "c1218bb4-da63-4901-d705-54e20f9953ff"
      },
      "source": [
        "\r\n",
        "model_acc4 = sum(1 for x,y in zip(data['threshold4'],data['labels']) if x == y) / len(data)\r\n",
        "mv4_acc_tiger = sum(1 for x,y in zip(data['threshold4'],data['labels']) if x == 1 == y ) / sum(data['labels'])\r\n",
        "mv4_acc_not_tiger = sum(1 for x,y in zip(data['threshold4'],data['labels']) if x == 0 == y) / (len(data) - sum(data['labels']))\r\n",
        "\r\n",
        "\r\n",
        "print(mv4_acc_tiger,mv4_acc_not_tiger,model_acc4)\r\n"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9191176470588235 0.7794117647058824 0.8492647058823529\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zt1jm0acxggw",
        "outputId": "253b3e81-06cd-430e-ed73-6daefe4a9894"
      },
      "source": [
        "mv_acc = sum(1 for x,y in zip(X_test['MV'],y_test) if x == y) / len(y_test)\n",
        "mv_acc_tiger = sum(1 for x,y in zip(X_test['MV'],y_test) if x == 1 == y ) / sum(y_test)\n",
        "mv_acc_not_tiger = sum(1 for x,y in zip(X_test['MV'],y_test) if x == 0 == y) / (len(y_test) - sum(y_test))\n",
        "\n",
        "\n",
        "print(mv_acc, mv_acc_tiger, mv_acc_not_tiger)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8666666666666667 0.8780487804878049 0.8571428571428571\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P12ZhR4o646x"
      },
      "source": [
        "weights_tiger=[]\n",
        "weights_not_tiger=[]\n",
        "#for i in range(len(data)):\n",
        "  #if data['labels'][i] == 1:\n",
        "    #weights_not_tiger.append(0)\n",
        "    #weights_tiger.append(1/(sum(data['labels'])))\n",
        "  #else:\n",
        "    #weights_not_tiger.append(1/(len(data) - sum(data['labels'])))\n",
        "    #weights_tiger.append(0)\n",
        "for i in range(len(X_test)):\n",
        "  if y_test[i] == 1:\n",
        "    weights_not_tiger.append(0)\n",
        "    weights_tiger.append(1/(sum(y_test)))\n",
        "  else:\n",
        "    weights_not_tiger.append(1/(len(X_test) - sum(y_test)))\n",
        "    weights_tiger.append(0)\n"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fc7XLje1A-q5"
      },
      "source": [
        "Logistic regression accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JCcGX9TX7bfG",
        "outputId": "db71565d-fa38-40ff-c26d-c54645a2605c"
      },
      "source": [
        "print('Overall accuracy: {:.4f} Not Tiger accuracy: {:.4f} Tiger accuracy: {:.4f}'.format(clf.score(X_test,y_test),clf.score(X_test,y_test,sample_weight=weights_not_tiger),clf.score(X_test,y_test,sample_weight=weights_tiger)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overall accuracy: 0.8778 Not Tiger accuracy: 0.8571 Tiger accuracy: 0.9024\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O5eRgDhhBBTk"
      },
      "source": [
        "SVM accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mAnAuNJk-peR",
        "outputId": "14648329-32b6-472f-f256-1988e09f8e39"
      },
      "source": [
        "print('Overall accuracy: {:.4f} Not Tiger accuracy: {:.4f} Tiger accuracy: {:.4f}'.format(clf2.score(X_test,y_test),clf2.score(X_test,y_test,sample_weight=weights_not_tiger),clf2.score(X_test,y_test,sample_weight=weights_tiger)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overall accuracy: 0.8667 Not Tiger accuracy: 0.8980 Tiger accuracy: 0.8293\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ITfnHp3C3kqY"
      },
      "source": [
        "X, y = data[[0,1,2,3,4]], data['labels'] \n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
        "clf = LogisticRegression(random_state=0).fit(X_train,y_train)\n",
        "clf2 = svm.SVC().fit(X_train,y_train)\n",
        "clf3 = tree.DecisionTreeClassifier().fit(X_train,y_train)"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "8jAWM62qWolx",
        "outputId": "89e47e50-39b3-48ae-b6fd-a3996a68ee84"
      },
      "source": [
        "results = pd.DataFrame()\n",
        "results['Overall Accuracy'] = [clf.score(X_test,y_test),clf2.score(X_test,y_test),clf3.score(X_test,y_test),mv_acc,model_acc4]\n",
        "results['Tiger Accuracy'] = [clf.score(X_test,y_test,sample_weight=weights_tiger),clf2.score(X_test,y_test,sample_weight=weights_tiger),clf3.score(X_test,y_test,sample_weight=weights_tiger),mv_acc_tiger,mv4_acc_tiger]\n",
        "results['Non-tiger Accuracy'] = [clf.score(X_test,y_test,sample_weight=weights_not_tiger),clf2.score(X_test,y_test,sample_weight=weights_not_tiger),clf3.score(X_test,y_test,sample_weight=weights_not_tiger),mv_acc_not_tiger,mv4_acc_not_tiger]\n",
        "results.index = ['LogReg','SVM','DT','Majority','Best model']\n",
        "results"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Overall Accuracy</th>\n",
              "      <th>Tiger Accuracy</th>\n",
              "      <th>Non-tiger Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>LogReg</th>\n",
              "      <td>0.900000</td>\n",
              "      <td>0.926829</td>\n",
              "      <td>0.877551</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SVM</th>\n",
              "      <td>0.911111</td>\n",
              "      <td>0.902439</td>\n",
              "      <td>0.918367</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DT</th>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.829268</td>\n",
              "      <td>0.836735</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Majority</th>\n",
              "      <td>0.866667</td>\n",
              "      <td>0.878049</td>\n",
              "      <td>0.857143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Best model</th>\n",
              "      <td>0.849265</td>\n",
              "      <td>0.919118</td>\n",
              "      <td>0.779412</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            Overall Accuracy  Tiger Accuracy  Non-tiger Accuracy\n",
              "LogReg              0.900000        0.926829            0.877551\n",
              "SVM                 0.911111        0.902439            0.918367\n",
              "DT                  0.833333        0.829268            0.836735\n",
              "Majority            0.866667        0.878049            0.857143\n",
              "Best model          0.849265        0.919118            0.779412"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HLocKx4s8TLf"
      },
      "source": [
        "results = results.sort_values('Overall Accuracy')"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 553
        },
        "id": "i3Q6Un2YV7U2",
        "outputId": "ed0b4b74-70b6-4e48-916f-2b00b5c3e998"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "labels = results.index\n",
        "\n",
        "\n",
        "x = np.arange(len(labels))  # the label locations\n",
        "width = 0.2  # the width of the bars\n",
        "fig, ax = plt.subplots(figsize=(18,9))\n",
        "rects1 = ax.bar(x - 1.1*width, results['Overall Accuracy'], width, label='Overall')\n",
        "rects2 = ax.bar(x, results['Tiger Accuracy'], width, label='Tiger')\n",
        "rects3 = ax.bar(x + 1.1*width, results['Non-tiger Accuracy'], width, label='Non-tiger')\n",
        "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
        "ax.set_ylabel('Accuracy')\n",
        "ax.set_title('Regression on the 5D data')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(labels)\n",
        "ax.legend()\n",
        "plt.show()"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1296x648 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}